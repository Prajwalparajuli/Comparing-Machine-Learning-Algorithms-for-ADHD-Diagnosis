{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce77282-9020-4b13-bd11-607233b50c15",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97894495-0032-44c9-afc8-dfd07da1717a",
   "metadata": {},
   "source": [
    "### Preprocessing the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e413e-58e8-4baa-9745-64c6be4be93f",
   "metadata": {},
   "source": [
    "You are working with resting-state fMRI data from the ADHD-200 dataset, specifically using the preprocessed time series extracted via the CC200 brain atlas. Each subject’s `.1D` file contains the BOLD signal for 190 brain regions (ROIs) across 149 timepoints, capturing the temporal dynamics of brain activity during rest. Rather than collapsing this temporal information into static functional connectivity (FC) matrices via Pearson correlation, you are retaining the full time series structure per region to train Recurrent Neural Networks (RNNs), which are well-suited for modeling sequential data. The objective is to classify subjects into ADHD and control groups by identifying temporal patterns in their brain activity.\n",
    "\n",
    "You will be using data from multiple acquisition sites within the ADHD-200 dataset, including **KKI, NeuroIMAGE, NYU, OHSU, Peking_1, Peking_2, Peking_3**, and **Pittsburgh**—all of which contain `.1D` time series files in the same format. These datasets will be merged and aligned with the corresponding phenotypic information (such as diagnosis, age, and medication status) to ensure accurate subject labeling during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2e6a3c-95fe-4893-8bb2-c249a0be20cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing site: KKI\n",
      " 83 valid subjects found in KKI\n",
      "\n",
      " Processing site: NYU\n",
      " 216 valid subjects found in NYU\n",
      "\n",
      " Processing site: OHSU\n",
      " 79 valid subjects found in OHSU\n",
      "\n",
      " Processing site: Peking_1\n",
      " 85 valid subjects found in Peking_1\n",
      "\n",
      " Processing site: Peking_2\n",
      " 67 valid subjects found in Peking_2\n",
      "\n",
      " Processing site: Peking_3\n",
      " 42 valid subjects found in Peking_3\n",
      "\n",
      " Processing site: NeuroIMAGE\n",
      " 48 valid subjects found in NeuroIMAGE\n",
      "\n",
      " Final dataset ready:\n",
      "X_rnn shape: (620, 260, 190)\n",
      "y_labels shape: (620,)\n",
      "subject_ids_all shape: (620,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# List of sites to process\n",
    "sites = [\"KKI\", \"NYU\", \"OHSU\", \"Peking_1\", \"Peking_2\", \"Peking_3\", \"NeuroIMAGE\"]\n",
    "\n",
    "# Set a fixed target sequence length (max seen = 256)\n",
    "TARGET_LENGTH = 260\n",
    "\n",
    "# Containers\n",
    "X_all = []\n",
    "y_all = []\n",
    "subject_ids_all = []\n",
    "\n",
    "# Function to pad or truncate time series\n",
    "def pad_to_length(array, target_length):\n",
    "    current_len = array.shape[0]\n",
    "    if current_len >= target_length:\n",
    "        return array[:target_length, :]\n",
    "    else:\n",
    "        pad_len = target_length - current_len\n",
    "        pad = np.zeros((pad_len, array.shape[1]))\n",
    "        return np.vstack([array, pad])\n",
    "\n",
    "# Main loop through sites\n",
    "for site in sites:\n",
    "    print(f\"\\n Processing site: {site}\")\n",
    "\n",
    "    pheno_csv = site + \"_phenotypic.csv\"\n",
    "    phenotype_path = os.path.join(\"fMRI/ADHD200_CC200_TCs_filtfix\", site, pheno_csv)\n",
    "\n",
    "    try:\n",
    "        phenotype_df = pd.read_csv(phenotype_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Phenotype file missing for {site}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    phenotype_df[\"Subject_ID\"] = phenotype_df[\"ScanDir ID\"].astype(str).str.zfill(7)\n",
    "    phenotype_df = phenotype_df[[\"Subject_ID\", \"DX\"]]\n",
    "    phenotype_df.set_index(\"Subject_ID\", inplace=True)\n",
    "\n",
    "    base_folder = f\"fMRI/ADHD200_CC200_TCs_filtfix/{site}/\"\n",
    "    rnn_data_dict = {}\n",
    "\n",
    "    if not os.path.isdir(base_folder):\n",
    "        print(f\" Base folder missing for {site}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    for subject_id in sorted(os.listdir(base_folder)):\n",
    "        subject_path = os.path.join(base_folder, subject_id)\n",
    "\n",
    "        if os.path.isdir(subject_path):\n",
    "            rest_paths = [\n",
    "                os.path.join(subject_path, f\"sfnwmrda{subject_id}_session_1_rest_1_cc200_TCs.1D\"),\n",
    "                os.path.join(subject_path, f\"sfnwmrda{subject_id}_session_1_rest_2_cc200_TCs.1D\"),\n",
    "                os.path.join(subject_path, f\"sfnwmrda{subject_id}_session_1_rest_3_cc200_TCs.1D\")\n",
    "            ]\n",
    "\n",
    "            merged_data = []\n",
    "            for path in rest_paths:\n",
    "                if os.path.exists(path):\n",
    "                    try:\n",
    "                        fmri_data = pd.read_csv(path, sep=r'\\s+', header=None, skiprows=1)\n",
    "                        fmri_data = fmri_data.iloc[:, 2:].astype(float).to_numpy()\n",
    "                        merged_data.append(fmri_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\" Error reading {path}: {e}\")\n",
    "\n",
    "            if merged_data:\n",
    "                full_time_series = np.vstack(merged_data)\n",
    "                rnn_data_dict[subject_id] = full_time_series\n",
    "\n",
    "    # Align with phenotype\n",
    "    valid_subjects = [sid for sid in rnn_data_dict if sid in phenotype_df.index]\n",
    "    print(f\" {len(valid_subjects)} valid subjects found in {site}\")\n",
    "\n",
    "    if valid_subjects:\n",
    "        X_site = np.stack([\n",
    "            pad_to_length(rnn_data_dict[sid], TARGET_LENGTH)\n",
    "            for sid in valid_subjects\n",
    "        ])\n",
    "        y_site = phenotype_df.loc[valid_subjects, 'DX'].astype(int).values\n",
    "\n",
    "        X_all.append(X_site)\n",
    "        y_all.append(y_site)\n",
    "        subject_ids_all.extend(valid_subjects)  # Keep subject ID order\n",
    "\n",
    "# Final dataset assembly\n",
    "X_rnn = np.concatenate(X_all, axis=0)\n",
    "y_labels = np.concatenate(y_all, axis=0)\n",
    "subject_ids_all = np.array(subject_ids_all)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"\\n Final dataset ready:\")\n",
    "print(f\"X_rnn shape: {X_rnn.shape}\")      # (n_subjects, 260, 190)\n",
    "print(f\"y_labels shape: {y_labels.shape}\")  # (n_subjects,)\n",
    "print(f\"subject_ids_all shape: {subject_ids_all.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5bbee5b-21c9-46c2-9a62-0bf9bcd2421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved to rnn_dataset_with_subjects.npz\n"
     ]
    }
   ],
   "source": [
    "# Save to disk\n",
    "np.savez(\"rnn_dataset_with_subjects.npz\", X=X_rnn, y=y_labels, subject_ids=subject_ids_all)\n",
    "print(\" Saved to rnn_dataset_with_subjects.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20681c8-9e1b-4476-8251-feb3aa489680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
