{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83df89ab-f2d3-4524-a88e-af44e1427133",
   "metadata": {},
   "source": [
    "## Multimodal Deep Neural Network (CNN + Attention + MLP) for ADHD Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7601b-58bc-4391-965b-21a6bcdc8c9d",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "Previous convolutional neural network (CNN) models trained solely on fMRI-derived features such as Functional Connectivity (FC), ReHo, and fALFF achieved modest classification accuracy (typically in the 50–60% range). However, traditional machine learning models (e.g., Random Forest, XGBoost) showed better performance when phenotypic information (age, sex, IQ, etc.) was incorporated.\n",
    "\n",
    "This motivates a shift toward **multimodal learning**, where both imaging and non-imaging data are utilized jointly. The proposed architecture addresses this by combining CNNs for imaging data, attention mechanisms to emphasize important spatial features, and a multi-layer perceptron (MLP) for structured phenotypic input.\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "1. **CNN Branches (for FC, ReHo, and fALFF)**\n",
    "   - Each imaging modality (FC, ReHo, fALFF) is passed through multiple 2D convolutional layers.\n",
    "   - Each branch includes layers of Conv2D → BatchNormalization → MaxPooling2D.\n",
    "   - The output is flattened and processed through attention layers.\n",
    "\n",
    "2. **Attention Mechanism**\n",
    "   - Learns to weight the most informative spatial features from CNN outputs.\n",
    "   - Helps improve model focus on brain regions contributing most to classification.\n",
    "\n",
    "3. **MLP Branch (for Phenotypic Data)**\n",
    "   - Handles non-image input such as age, sex, IQ, medication status, and site.\n",
    "   - Structured as Dense → Dropout → Dense layers.\n",
    "\n",
    "4. **Fusion Layer**\n",
    "   - The outputs from all CNN-attention branches and the MLP are concatenated.\n",
    "   - Followed by fully connected layers to perform final binary classification using sigmoid activation.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Goals\n",
    "\n",
    "- Align input shapes and normalization across modalities.\n",
    "- Enable the CNN branches to learn distinct patterns per fMRI modality.\n",
    "- Integrate attention to improve interpretability and classification.\n",
    "- Train the model end-to-end to optimize for accuracy and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f81b3ac-7d8f-443a-a90c-37ed9cae783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n",
    "    BatchNormalization, concatenate, GlobalAveragePooling2D, \n",
    "    Reshape, Multiply\n",
    ")\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import random\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds(42)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb71aee-6a8c-4f52-a981-2fe1c2322787",
   "metadata": {},
   "source": [
    "### Importing Necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01892fa-556a-4450-88ed-58465cb69094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DX</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>17945</th>\n",
       "      <th>17946</th>\n",
       "      <th>17947</th>\n",
       "      <th>17948</th>\n",
       "      <th>17949</th>\n",
       "      <th>17950</th>\n",
       "      <th>17951</th>\n",
       "      <th>17952</th>\n",
       "      <th>17953</th>\n",
       "      <th>17954</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018959</th>\n",
       "      <td>0</td>\n",
       "      <td>0.082767</td>\n",
       "      <td>-0.202121</td>\n",
       "      <td>-0.253291</td>\n",
       "      <td>0.143162</td>\n",
       "      <td>-0.212533</td>\n",
       "      <td>0.572503</td>\n",
       "      <td>-0.346531</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112687</td>\n",
       "      <td>0.171248</td>\n",
       "      <td>-0.073971</td>\n",
       "      <td>-0.413591</td>\n",
       "      <td>0.238855</td>\n",
       "      <td>0.300857</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.658069</td>\n",
       "      <td>-0.052805</td>\n",
       "      <td>0.145006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019436</th>\n",
       "      <td>1</td>\n",
       "      <td>0.216872</td>\n",
       "      <td>-0.055456</td>\n",
       "      <td>0.274632</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.318357</td>\n",
       "      <td>0.334924</td>\n",
       "      <td>-0.285290</td>\n",
       "      <td>-0.093749</td>\n",
       "      <td>0.051842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.466976</td>\n",
       "      <td>-0.189028</td>\n",
       "      <td>0.048556</td>\n",
       "      <td>-0.476408</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0.424513</td>\n",
       "      <td>0.450524</td>\n",
       "      <td>-0.022595</td>\n",
       "      <td>0.231871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043241</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.060757</td>\n",
       "      <td>0.218841</td>\n",
       "      <td>-0.220541</td>\n",
       "      <td>-0.009787</td>\n",
       "      <td>-0.018797</td>\n",
       "      <td>0.102055</td>\n",
       "      <td>-0.207456</td>\n",
       "      <td>-0.332605</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118490</td>\n",
       "      <td>-0.123154</td>\n",
       "      <td>-0.287799</td>\n",
       "      <td>-0.404065</td>\n",
       "      <td>0.111559</td>\n",
       "      <td>-0.233413</td>\n",
       "      <td>-0.120683</td>\n",
       "      <td>0.083335</td>\n",
       "      <td>-0.058685</td>\n",
       "      <td>0.343333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266183</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.063801</td>\n",
       "      <td>0.061519</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>0.135984</td>\n",
       "      <td>0.164675</td>\n",
       "      <td>0.174189</td>\n",
       "      <td>-0.108558</td>\n",
       "      <td>-0.031854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256891</td>\n",
       "      <td>-0.414658</td>\n",
       "      <td>-0.549495</td>\n",
       "      <td>0.543498</td>\n",
       "      <td>0.292311</td>\n",
       "      <td>0.164908</td>\n",
       "      <td>-0.031181</td>\n",
       "      <td>0.084472</td>\n",
       "      <td>-0.235999</td>\n",
       "      <td>-0.609832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535233</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>0.380467</td>\n",
       "      <td>0.404897</td>\n",
       "      <td>0.422225</td>\n",
       "      <td>0.546707</td>\n",
       "      <td>-0.022366</td>\n",
       "      <td>0.218834</td>\n",
       "      <td>0.274712</td>\n",
       "      <td>0.191838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238173</td>\n",
       "      <td>-0.059068</td>\n",
       "      <td>-0.020537</td>\n",
       "      <td>-0.465405</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.410916</td>\n",
       "      <td>0.510831</td>\n",
       "      <td>-0.106011</td>\n",
       "      <td>0.137268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669389</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.136454</td>\n",
       "      <td>-0.065583</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.460014</td>\n",
       "      <td>0.306935</td>\n",
       "      <td>0.176286</td>\n",
       "      <td>-0.345477</td>\n",
       "      <td>0.164890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206593</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>0.034391</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.386416</td>\n",
       "      <td>0.166788</td>\n",
       "      <td>0.555021</td>\n",
       "      <td>0.308751</td>\n",
       "      <td>0.346726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383713</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>-0.314136</td>\n",
       "      <td>-0.223007</td>\n",
       "      <td>0.475450</td>\n",
       "      <td>0.595427</td>\n",
       "      <td>0.529921</td>\n",
       "      <td>-0.154340</td>\n",
       "      <td>-0.193150</td>\n",
       "      <td>-0.176574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274156</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>-0.183968</td>\n",
       "      <td>-0.383677</td>\n",
       "      <td>0.533130</td>\n",
       "      <td>0.236219</td>\n",
       "      <td>0.114466</td>\n",
       "      <td>0.385278</td>\n",
       "      <td>0.143373</td>\n",
       "      <td>0.421396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477085</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.619545</td>\n",
       "      <td>-0.075170</td>\n",
       "      <td>-0.074883</td>\n",
       "      <td>0.100222</td>\n",
       "      <td>0.329930</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>-0.110990</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>-0.494886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137766</td>\n",
       "      <td>0.480185</td>\n",
       "      <td>0.059669</td>\n",
       "      <td>0.074272</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.376793</td>\n",
       "      <td>0.156937</td>\n",
       "      <td>0.225204</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.042565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994085</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.298730</td>\n",
       "      <td>0.156669</td>\n",
       "      <td>-0.152175</td>\n",
       "      <td>0.284072</td>\n",
       "      <td>0.307652</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>-0.070846</td>\n",
       "      <td>-0.309843</td>\n",
       "      <td>-0.055744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386502</td>\n",
       "      <td>0.386439</td>\n",
       "      <td>-0.201634</td>\n",
       "      <td>-0.290110</td>\n",
       "      <td>-0.528532</td>\n",
       "      <td>-0.041827</td>\n",
       "      <td>0.313892</td>\n",
       "      <td>0.230130</td>\n",
       "      <td>-0.464864</td>\n",
       "      <td>-0.326013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191384</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116118</td>\n",
       "      <td>-0.267212</td>\n",
       "      <td>-0.054718</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>0.368004</td>\n",
       "      <td>0.280456</td>\n",
       "      <td>0.239108</td>\n",
       "      <td>-0.187744</td>\n",
       "      <td>0.156688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096180</td>\n",
       "      <td>0.397491</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>-0.099426</td>\n",
       "      <td>0.327180</td>\n",
       "      <td>0.070010</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.590307</td>\n",
       "      <td>-0.188008</td>\n",
       "      <td>-0.253398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 17956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DX         0         1         2         3         4         5  \\\n",
       "Subject ID                                                                   \n",
       "1018959      0  0.082767 -0.202121 -0.253291  0.143162 -0.212533  0.572503   \n",
       "1019436      1  0.216872 -0.055456  0.274632  0.057173  0.318357  0.334924   \n",
       "1043241      0 -0.060757  0.218841 -0.220541 -0.009787 -0.018797  0.102055   \n",
       "1266183      0 -0.063801  0.061519 -0.011792  0.016329  0.135984  0.164675   \n",
       "1535233      0  0.022708  0.380467  0.404897  0.422225  0.546707 -0.022366   \n",
       "...         ..       ...       ...       ...       ...       ...       ...   \n",
       "5669389      0 -0.136454 -0.065583  0.017311  0.052200  0.460014  0.306935   \n",
       "6383713      1  0.004203 -0.314136 -0.223007  0.475450  0.595427  0.529921   \n",
       "6477085      0 -0.619545 -0.075170 -0.074883  0.100222  0.329930  0.071147   \n",
       "7994085      0 -0.298730  0.156669 -0.152175  0.284072  0.307652  0.079670   \n",
       "8191384      0  0.116118 -0.267212 -0.054718  0.098136  0.368004  0.280456   \n",
       "\n",
       "                   6         7         8  ...     17945     17946     17947  \\\n",
       "Subject ID                                ...                                 \n",
       "1018959    -0.346531  0.010921  0.014705  ...  0.112687  0.171248 -0.073971   \n",
       "1019436    -0.285290 -0.093749  0.051842  ... -0.466976 -0.189028  0.048556   \n",
       "1043241    -0.207456 -0.332605  0.157679  ... -0.118490 -0.123154 -0.287799   \n",
       "1266183     0.174189 -0.108558 -0.031854  ... -0.256891 -0.414658 -0.549495   \n",
       "1535233     0.218834  0.274712  0.191838  ... -0.238173 -0.059068 -0.020537   \n",
       "...              ...       ...       ...  ...       ...       ...       ...   \n",
       "5669389     0.176286 -0.345477  0.164890  ...  0.206593  0.249444 -0.039177   \n",
       "6383713    -0.154340 -0.193150 -0.176574  ...  0.274156  0.141414 -0.183968   \n",
       "6477085    -0.110990  0.133600 -0.494886  ...  0.137766  0.480185  0.059669   \n",
       "7994085    -0.070846 -0.309843 -0.055744  ... -0.386502  0.386439 -0.201634   \n",
       "8191384     0.239108 -0.187744  0.156688  ...  0.096180  0.397491  0.099164   \n",
       "\n",
       "               17948     17949     17950     17951     17952     17953  \\\n",
       "Subject ID                                                               \n",
       "1018959    -0.413591  0.238855  0.300857  0.177778  0.658069 -0.052805   \n",
       "1019436    -0.476408  0.064047 -0.008339  0.424513  0.450524 -0.022595   \n",
       "1043241    -0.404065  0.111559 -0.233413 -0.120683  0.083335 -0.058685   \n",
       "1266183     0.543498  0.292311  0.164908 -0.031181  0.084472 -0.235999   \n",
       "1535233    -0.465405  0.143333  0.194637  0.410916  0.510831 -0.106011   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "5669389     0.034391  0.666300  0.386416  0.166788  0.555021  0.308751   \n",
       "6383713    -0.383677  0.533130  0.236219  0.114466  0.385278  0.143373   \n",
       "6477085     0.074272  0.309700  0.376793  0.156937  0.225204  0.034719   \n",
       "7994085    -0.290110 -0.528532 -0.041827  0.313892  0.230130 -0.464864   \n",
       "8191384    -0.099426  0.327180  0.070010  0.002184  0.590307 -0.188008   \n",
       "\n",
       "               17954  \n",
       "Subject ID            \n",
       "1018959     0.145006  \n",
       "1019436     0.231871  \n",
       "1043241     0.343333  \n",
       "1266183    -0.609832  \n",
       "1535233     0.137268  \n",
       "...              ...  \n",
       "5669389     0.346726  \n",
       "6383713     0.421396  \n",
       "6477085     0.042565  \n",
       "7994085    -0.326013  \n",
       "8191384    -0.253398  \n",
       "\n",
       "[620 rows x 17956 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DX</th>\n",
       "      <th>ReHo_1</th>\n",
       "      <th>ReHo_2</th>\n",
       "      <th>ReHo_3</th>\n",
       "      <th>ReHo_4</th>\n",
       "      <th>ReHo_5</th>\n",
       "      <th>ReHo_6</th>\n",
       "      <th>ReHo_7</th>\n",
       "      <th>ReHo_8</th>\n",
       "      <th>ReHo_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ReHo_181</th>\n",
       "      <th>ReHo_182</th>\n",
       "      <th>ReHo_183</th>\n",
       "      <th>ReHo_184</th>\n",
       "      <th>ReHo_185</th>\n",
       "      <th>ReHo_186</th>\n",
       "      <th>ReHo_187</th>\n",
       "      <th>ReHo_188</th>\n",
       "      <th>ReHo_189</th>\n",
       "      <th>ReHo_190</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScanDir ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018959</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000693</td>\n",
       "      <td>-0.002784</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.004366</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.012670</td>\n",
       "      <td>-0.006496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019436</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>-0.028085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>-0.010433</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>-0.026912</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.014229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043241</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.025526</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>-0.003846</td>\n",
       "      <td>-0.008930</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>0.027966</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>0.029532</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>-0.010745</td>\n",
       "      <td>-0.009088</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>-0.008181</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.007629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266183</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>-0.020910</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>-0.028537</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>-0.043965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.016781</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>-0.011874</td>\n",
       "      <td>0.012493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535233</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.037103</td>\n",
       "      <td>0.037410</td>\n",
       "      <td>0.053010</td>\n",
       "      <td>-0.005686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033017</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.008167</td>\n",
       "      <td>-0.052603</td>\n",
       "      <td>0.034772</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.030917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669389</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.031368</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>-0.033296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029162</td>\n",
       "      <td>-0.003820</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>-0.027044</td>\n",
       "      <td>0.047881</td>\n",
       "      <td>-0.004888</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383713</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.011001</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.045278</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>-0.010543</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>-0.002366</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>-0.011299</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.053413</td>\n",
       "      <td>-0.014896</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>0.029257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477085</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.090311</td>\n",
       "      <td>0.077690</td>\n",
       "      <td>0.036559</td>\n",
       "      <td>-0.020320</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>-0.008798</td>\n",
       "      <td>0.056555</td>\n",
       "      <td>-0.011541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046824</td>\n",
       "      <td>0.049709</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.057467</td>\n",
       "      <td>0.073680</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>0.080742</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>0.056369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994085</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.009549</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.017457</td>\n",
       "      <td>0.018368</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>-0.006689</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>-0.007553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191384</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>-0.010241</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>-0.022422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>-0.010769</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>-0.008291</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.015280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DX    ReHo_1    ReHo_2    ReHo_3    ReHo_4    ReHo_5    ReHo_6  \\\n",
       "ScanDir ID                                                                   \n",
       "1018959      0 -0.000693 -0.002784  0.005485  0.013734  0.009531  0.012442   \n",
       "1019436      1  0.001641  0.000157 -0.000600  0.008507 -0.005215  0.021348   \n",
       "1043241      0 -0.025526 -0.007973 -0.003846 -0.008930  0.002580  0.012220   \n",
       "1266183      0  0.017338 -0.020910  0.026822 -0.028537  0.004145  0.018429   \n",
       "1535233      0  0.025408 -0.004181  0.019778  0.010639  0.042414  0.037103   \n",
       "...         ..       ...       ...       ...       ...       ...       ...   \n",
       "5669389      0  0.041583  0.031368  0.018500  0.003853  0.005902  0.035916   \n",
       "6383713      1 -0.011001  0.023553  0.045278  0.023125 -0.010543  0.009812   \n",
       "6477085      0 -0.090311  0.077690  0.036559 -0.020320  0.005736 -0.015036   \n",
       "7994085      0 -0.009549  0.003129  0.000436  0.005846  0.003584  0.004464   \n",
       "8191384      0  0.012687  0.027030 -0.001901  0.011772  0.006331  0.015360   \n",
       "\n",
       "              ReHo_7    ReHo_8    ReHo_9  ...  ReHo_181  ReHo_182  ReHo_183  \\\n",
       "ScanDir ID                                ...                                 \n",
       "1018959     0.015524  0.004018  0.013782  ... -0.000228 -0.004366  0.007430   \n",
       "1019436     0.037630 -0.002221 -0.028085  ...  0.005336  0.026657 -0.010433   \n",
       "1043241     0.027966  0.006901  0.004053  ... -0.004057  0.029532  0.017034   \n",
       "1266183     0.023084  0.018687 -0.043965  ... -0.009916  0.024002  0.001976   \n",
       "1535233     0.037410  0.053010 -0.005686  ... -0.033017 -0.009099 -0.008167   \n",
       "...              ...       ...       ...  ...       ...       ...       ...   \n",
       "5669389     0.007781  0.037332 -0.033296  ...  0.029162 -0.003820  0.023286   \n",
       "6383713    -0.002366  0.047632  0.009774  ...  0.023663 -0.011299  0.034275   \n",
       "6477085    -0.008798  0.056555 -0.011541  ...  0.046824  0.049709  0.059777   \n",
       "7994085     0.017457  0.018368 -0.005317  ...  0.002915  0.000692 -0.005344   \n",
       "8191384    -0.010241  0.034581 -0.022422  ...  0.016688 -0.010769  0.005099   \n",
       "\n",
       "            ReHo_184  ReHo_185  ReHo_186  ReHo_187  ReHo_188  ReHo_189  \\\n",
       "ScanDir ID                                                               \n",
       "1018959     0.014627  0.001317 -0.006228  0.001716 -0.000210 -0.012670   \n",
       "1019436     0.010363  0.016745  0.020867 -0.026912 -0.010929  0.002073   \n",
       "1043241     0.011103 -0.010745 -0.009088  0.008249 -0.008181 -0.001200   \n",
       "1266183    -0.016781  0.019819  0.008669  0.015358 -0.016745 -0.011874   \n",
       "1535233    -0.052603  0.034772 -0.018005  0.037081  0.002573  0.026957   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "5669389    -0.027044  0.047881 -0.004888  0.033479  0.043651  0.021794   \n",
       "6383713     0.012848  0.053413 -0.014896  0.022261  0.042729  0.033602   \n",
       "6477085     0.007273  0.057467  0.073680  0.053626  0.080742  0.041598   \n",
       "7994085    -0.006689  0.002440  0.005350  0.000327 -0.005584  0.002570   \n",
       "8191384    -0.029147  0.025015 -0.008291  0.034371  0.013742  0.004346   \n",
       "\n",
       "            ReHo_190  \n",
       "ScanDir ID            \n",
       "1018959    -0.006496  \n",
       "1019436    -0.014229  \n",
       "1043241    -0.007629  \n",
       "1266183     0.012493  \n",
       "1535233     0.030917  \n",
       "...              ...  \n",
       "5669389     0.022059  \n",
       "6383713     0.029257  \n",
       "6477085     0.056369  \n",
       "7994085    -0.007553  \n",
       "8191384     0.015280  \n",
       "\n",
       "[620 rows x 191 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018959</th>\n",
       "      <td>0.440059</td>\n",
       "      <td>0.654038</td>\n",
       "      <td>0.604660</td>\n",
       "      <td>0.539188</td>\n",
       "      <td>0.427841</td>\n",
       "      <td>0.556644</td>\n",
       "      <td>0.456504</td>\n",
       "      <td>0.500982</td>\n",
       "      <td>0.631251</td>\n",
       "      <td>0.613161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375033</td>\n",
       "      <td>0.613263</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.468351</td>\n",
       "      <td>0.381020</td>\n",
       "      <td>0.650361</td>\n",
       "      <td>0.684567</td>\n",
       "      <td>0.676759</td>\n",
       "      <td>0.612947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019436</th>\n",
       "      <td>0.756351</td>\n",
       "      <td>0.527825</td>\n",
       "      <td>0.619720</td>\n",
       "      <td>0.466123</td>\n",
       "      <td>0.497030</td>\n",
       "      <td>0.384478</td>\n",
       "      <td>0.546645</td>\n",
       "      <td>0.465267</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>0.561305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492485</td>\n",
       "      <td>0.475318</td>\n",
       "      <td>0.603202</td>\n",
       "      <td>0.554377</td>\n",
       "      <td>0.620290</td>\n",
       "      <td>0.637574</td>\n",
       "      <td>0.674873</td>\n",
       "      <td>0.568847</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043241</th>\n",
       "      <td>0.730804</td>\n",
       "      <td>0.413692</td>\n",
       "      <td>0.591623</td>\n",
       "      <td>0.642186</td>\n",
       "      <td>0.434255</td>\n",
       "      <td>0.555075</td>\n",
       "      <td>0.479140</td>\n",
       "      <td>0.540595</td>\n",
       "      <td>0.621012</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584502</td>\n",
       "      <td>0.637769</td>\n",
       "      <td>0.727549</td>\n",
       "      <td>0.557828</td>\n",
       "      <td>0.637839</td>\n",
       "      <td>0.755363</td>\n",
       "      <td>0.547045</td>\n",
       "      <td>0.572328</td>\n",
       "      <td>0.555771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266183</th>\n",
       "      <td>0.324953</td>\n",
       "      <td>0.566304</td>\n",
       "      <td>0.556289</td>\n",
       "      <td>0.538490</td>\n",
       "      <td>0.495830</td>\n",
       "      <td>0.416628</td>\n",
       "      <td>0.328429</td>\n",
       "      <td>0.372241</td>\n",
       "      <td>0.477356</td>\n",
       "      <td>0.531180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448431</td>\n",
       "      <td>0.631884</td>\n",
       "      <td>0.497536</td>\n",
       "      <td>0.458568</td>\n",
       "      <td>0.515995</td>\n",
       "      <td>0.474847</td>\n",
       "      <td>0.524475</td>\n",
       "      <td>0.535504</td>\n",
       "      <td>0.719011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535233</th>\n",
       "      <td>0.544618</td>\n",
       "      <td>0.434999</td>\n",
       "      <td>0.646133</td>\n",
       "      <td>0.715492</td>\n",
       "      <td>0.669921</td>\n",
       "      <td>0.582833</td>\n",
       "      <td>0.459039</td>\n",
       "      <td>0.543931</td>\n",
       "      <td>0.610697</td>\n",
       "      <td>0.451788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539778</td>\n",
       "      <td>0.641483</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.642956</td>\n",
       "      <td>0.653623</td>\n",
       "      <td>0.727645</td>\n",
       "      <td>0.405513</td>\n",
       "      <td>0.391241</td>\n",
       "      <td>0.657757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669389</th>\n",
       "      <td>0.256059</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.668876</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.398631</td>\n",
       "      <td>0.544864</td>\n",
       "      <td>0.429395</td>\n",
       "      <td>0.567268</td>\n",
       "      <td>0.646345</td>\n",
       "      <td>0.525099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316761</td>\n",
       "      <td>0.561301</td>\n",
       "      <td>0.515058</td>\n",
       "      <td>0.305818</td>\n",
       "      <td>0.312659</td>\n",
       "      <td>0.622423</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>0.537619</td>\n",
       "      <td>0.563718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383713</th>\n",
       "      <td>0.229875</td>\n",
       "      <td>0.445956</td>\n",
       "      <td>0.446567</td>\n",
       "      <td>0.515856</td>\n",
       "      <td>0.507962</td>\n",
       "      <td>0.443237</td>\n",
       "      <td>0.339974</td>\n",
       "      <td>0.519716</td>\n",
       "      <td>0.503483</td>\n",
       "      <td>0.485144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332223</td>\n",
       "      <td>0.643870</td>\n",
       "      <td>0.490933</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.346755</td>\n",
       "      <td>0.377433</td>\n",
       "      <td>0.524141</td>\n",
       "      <td>0.334546</td>\n",
       "      <td>0.418346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477085</th>\n",
       "      <td>0.340038</td>\n",
       "      <td>0.422289</td>\n",
       "      <td>0.542378</td>\n",
       "      <td>0.624692</td>\n",
       "      <td>0.546239</td>\n",
       "      <td>0.549973</td>\n",
       "      <td>0.443172</td>\n",
       "      <td>0.644051</td>\n",
       "      <td>0.535838</td>\n",
       "      <td>0.474425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383385</td>\n",
       "      <td>0.465567</td>\n",
       "      <td>0.499877</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.394593</td>\n",
       "      <td>0.424113</td>\n",
       "      <td>0.480928</td>\n",
       "      <td>0.514339</td>\n",
       "      <td>0.584390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994085</th>\n",
       "      <td>0.391632</td>\n",
       "      <td>0.510163</td>\n",
       "      <td>0.715460</td>\n",
       "      <td>0.562021</td>\n",
       "      <td>0.546323</td>\n",
       "      <td>0.440242</td>\n",
       "      <td>0.350638</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.689878</td>\n",
       "      <td>0.572333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567139</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.644709</td>\n",
       "      <td>0.422675</td>\n",
       "      <td>0.511961</td>\n",
       "      <td>0.565686</td>\n",
       "      <td>0.756029</td>\n",
       "      <td>0.552888</td>\n",
       "      <td>0.624066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191384</th>\n",
       "      <td>0.357898</td>\n",
       "      <td>0.320334</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>0.423940</td>\n",
       "      <td>0.541160</td>\n",
       "      <td>0.553921</td>\n",
       "      <td>0.421821</td>\n",
       "      <td>0.573894</td>\n",
       "      <td>0.549285</td>\n",
       "      <td>0.490957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268012</td>\n",
       "      <td>0.643829</td>\n",
       "      <td>0.701483</td>\n",
       "      <td>0.290839</td>\n",
       "      <td>0.433854</td>\n",
       "      <td>0.579414</td>\n",
       "      <td>0.588057</td>\n",
       "      <td>0.575549</td>\n",
       "      <td>0.525868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "Subject ID                                                               \n",
       "1018959     0.440059  0.654038  0.604660  0.539188  0.427841  0.556644   \n",
       "1019436     0.756351  0.527825  0.619720  0.466123  0.497030  0.384478   \n",
       "1043241     0.730804  0.413692  0.591623  0.642186  0.434255  0.555075   \n",
       "1266183     0.324953  0.566304  0.556289  0.538490  0.495830  0.416628   \n",
       "1535233     0.544618  0.434999  0.646133  0.715492  0.669921  0.582833   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "5669389     0.256059  0.476082  0.668876  0.450693  0.398631  0.544864   \n",
       "6383713     0.229875  0.445956  0.446567  0.515856  0.507962  0.443237   \n",
       "6477085     0.340038  0.422289  0.542378  0.624692  0.546239  0.549973   \n",
       "7994085     0.391632  0.510163  0.715460  0.562021  0.546323  0.440242   \n",
       "8191384     0.357898  0.320334  0.537955  0.423940  0.541160  0.553921   \n",
       "\n",
       "                   6         7         8         9  ...       181       182  \\\n",
       "Subject ID                                          ...                       \n",
       "1018959     0.456504  0.500982  0.631251  0.613161  ...  0.375033  0.613263   \n",
       "1019436     0.546645  0.465267  0.588696  0.561305  ...  0.492485  0.475318   \n",
       "1043241     0.479140  0.540595  0.621012  0.618000  ...  0.584502  0.637769   \n",
       "1266183     0.328429  0.372241  0.477356  0.531180  ...  0.448431  0.631884   \n",
       "1535233     0.459039  0.543931  0.610697  0.451788  ...  0.539778  0.641483   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "5669389     0.429395  0.567268  0.646345  0.525099  ...  0.316761  0.561301   \n",
       "6383713     0.339974  0.519716  0.503483  0.485144  ...  0.332223  0.643870   \n",
       "6477085     0.443172  0.644051  0.535838  0.474425  ...  0.383385  0.465567   \n",
       "7994085     0.350638  0.617332  0.689878  0.572333  ...  0.567139  0.657349   \n",
       "8191384     0.421821  0.573894  0.549285  0.490957  ...  0.268012  0.643829   \n",
       "\n",
       "                 183       184       185       186       187       188  \\\n",
       "Subject ID                                                               \n",
       "1018959     0.645600  0.468351  0.381020  0.650361  0.684567  0.676759   \n",
       "1019436     0.603202  0.554377  0.620290  0.637574  0.674873  0.568847   \n",
       "1043241     0.727549  0.557828  0.637839  0.755363  0.547045  0.572328   \n",
       "1266183     0.497536  0.458568  0.515995  0.474847  0.524475  0.535504   \n",
       "1535233     0.671250  0.642956  0.653623  0.727645  0.405513  0.391241   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "5669389     0.515058  0.305818  0.312659  0.622423  0.618545  0.537619   \n",
       "6383713     0.490933  0.395509  0.346755  0.377433  0.524141  0.334546   \n",
       "6477085     0.499877  0.352168  0.394593  0.424113  0.480928  0.514339   \n",
       "7994085     0.644709  0.422675  0.511961  0.565686  0.756029  0.552888   \n",
       "8191384     0.701483  0.290839  0.433854  0.579414  0.588057  0.575549   \n",
       "\n",
       "                 189  DX  \n",
       "Subject ID                \n",
       "1018959     0.612947   0  \n",
       "1019436     0.609281   1  \n",
       "1043241     0.555771   0  \n",
       "1266183     0.719011   0  \n",
       "1535233     0.657757   0  \n",
       "...              ...  ..  \n",
       "5669389     0.563718   0  \n",
       "6383713     0.418346   1  \n",
       "6477085     0.584390   0  \n",
       "7994085     0.624066   0  \n",
       "8191384     0.525868   0  \n",
       "\n",
       "[620 rows x 191 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "FC_data = pd.read_csv(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/Preprocessed FC/Merged_FC.csv\", index_col = 0)\n",
    "FC_data.index.name = \"Subject ID\"\n",
    "\n",
    "Reho = pd.read_csv(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/Preprocessed ReHo/All_ReHo.csv\", index_col = 0)\n",
    "Reho.index.name = \"Subject ID\"\n",
    "\n",
    "falff = pd.read_csv(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/Preprocessed fALFF/All_falff.csv\", index_col = 0)\n",
    "falff.index.name = \"Subject ID\"\n",
    "\n",
    "FC_pheno_data = pd.read_csv(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/Preprocessed FC matrix with Pheno/FC_Merged.csv\", index_col = 0)\n",
    "FC_pheno_data.index.name = \"Subject ID\"\n",
    "\n",
    "FC_data['DX'] = FC_data['DX'].apply(lambda x: 1 if x > 0 else 0)\n",
    "Reho['DX'] = Reho['DX'].apply(lambda x: 1 if x > 0 else 0)\n",
    "falff['DX'] = falff['DX'].apply(lambda x: 1 if x > 0 else 0)\n",
    "Reho = Reho.set_index('ScanDir ID')\n",
    "\n",
    "FC_data\n",
    "Reho\n",
    "falff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd36776-145b-4853-bc1b-c3b811907f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inattentive</th>\n",
       "      <th>Hyper/Impulsive</th>\n",
       "      <th>Verbal IQ</th>\n",
       "      <th>Performance IQ</th>\n",
       "      <th>Full4 IQ</th>\n",
       "      <th>Med Status</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018959</th>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019436</th>\n",
       "      <td>60.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043241</th>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266183</th>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535233</th>\n",
       "      <td>41.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669389</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383713</th>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477085</th>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994085</th>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191384</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Inattentive  Hyper/Impulsive  Verbal IQ  Performance IQ  Full4 IQ  \\\n",
       "Subject ID                                                                      \n",
       "1018959            47.0             44.0       99.0           115.0     103.0   \n",
       "1019436            60.0             66.0      124.0           108.0     122.0   \n",
       "1043241            40.0             43.0      128.0           106.0     120.0   \n",
       "1266183            44.0             43.0      136.0            96.0     120.0   \n",
       "1535233            41.0             43.0      106.0           135.0     122.0   \n",
       "...                 ...              ...        ...             ...       ...   \n",
       "5669389            15.0              9.0      120.0            97.0     110.0   \n",
       "6383713            29.0             32.0      115.0            91.0     104.0   \n",
       "6477085            13.0             12.0      115.0           112.0     115.0   \n",
       "7994085            23.0             15.0       89.0            86.0      86.0   \n",
       "8191384            11.0             10.0      104.0            81.0      92.0   \n",
       "\n",
       "            Med Status  DX  \n",
       "Subject ID                  \n",
       "1018959              1   0  \n",
       "1019436              1   1  \n",
       "1043241              1   0  \n",
       "1266183              1   0  \n",
       "1535233              1   0  \n",
       "...                ...  ..  \n",
       "5669389              1   0  \n",
       "6383713              1   1  \n",
       "6477085              1   0  \n",
       "7994085              1   0  \n",
       "8191384              1   0  \n",
       "\n",
       "[493 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotype_cols = ['Inattentive', 'Hyper/Impulsive', 'Verbal IQ', \n",
    "                  'Performance IQ', 'Full4 IQ', 'Med Status', 'DX']\n",
    "pheno_data = FC_pheno_data[phenotype_cols].copy()\n",
    "pheno_data.index.name = 'Subject ID'\n",
    "pheno_data['DX'] = pheno_data['DX'].apply(lambda x: 1 if x > 0 else 0)\n",
    "pheno_data\n",
    "\n",
    "# Step: Find common subjects between phenotype and fMRI data\n",
    "common_subjects = pheno_data.index.intersection(FC_data.index)\n",
    "\n",
    "# Step: Filter all datasets to include only those subjects\n",
    "FC_data = FC_data.loc[common_subjects]\n",
    "Reho = Reho.loc[common_subjects]\n",
    "falff = falff.loc[common_subjects]\n",
    "pheno_data = pheno_data.loc[common_subjects]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7fd7d-2aad-42ee-8b9a-66ff710b4f70",
   "metadata": {},
   "source": [
    "### Shaping the Data into 2D with 3 channels with FC, ReHo and fALFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7447fb2f-7b41-4354-8977-7a1768ceab81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 190, 190, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_FC = FC_data.drop(columns = \"DX\").values\n",
    "y_FC = FC_data[\"DX\"].values\n",
    "\n",
    "X_Reho = Reho.drop(columns= \"DX\").values\n",
    "X_Reho = X_Reho.astype(float)\n",
    "y_Reho = Reho[\"DX\"].values\n",
    "\n",
    "X_falff = falff.drop(columns=\"DX\").values\n",
    "X_falff = X_falff.astype(float)\n",
    "y_falff = falff[\"DX\"].values\n",
    "\n",
    "\n",
    "\n",
    "# Making flat FC data into symmetric Matrix\n",
    "n_regions = 190 \n",
    "triu_indices = np.triu_indices(n_regions, k = 1)\n",
    "\n",
    "fc_matrices = []\n",
    "\n",
    "for row in X_FC:\n",
    "    mat = np.zeros((n_regions, n_regions))\n",
    "    mat[triu_indices] = row\n",
    "    mat += mat.T\n",
    "    fc_matrices.append(mat)\n",
    "\n",
    "X_fc_reshape = np.array(fc_matrices)\n",
    "\n",
    "# ReHo --> Outer Product\n",
    "reho_matrices = np.array([np.outer(row, row) for row in X_Reho])\n",
    "X_reho_reshape = reho_matrices\n",
    "\n",
    "# fALFF ---> Outer Product\n",
    "falff_matrices = np.array([np.outer(row, row) for row in X_falff])\n",
    "X_falff_reshape = falff_matrices\n",
    "\n",
    "# Function to apply z-score normalization per matrix\n",
    "def normalize_per_subject(matrices):\n",
    "    normalized = []\n",
    "    for mat in matrices:\n",
    "        flat = mat.flatten()\n",
    "        norm_flat = zscore(flat)\n",
    "        norm_mat = norm_flat.reshape(mat.shape)\n",
    "        normalized.append(norm_mat)\n",
    "    return np.array(normalized)\n",
    "\n",
    "# Apply to FC, ReHo, fALFF\n",
    "X_fc_reshaped = normalize_per_subject(X_fc_reshape)\n",
    "X_reho_reshaped = normalize_per_subject(X_reho_reshape)\n",
    "X_falff_reshaped = normalize_per_subject(X_falff_reshape)\n",
    "\n",
    "\n",
    "X_combined = np.stack([X_fc_reshaped,\n",
    "                      X_reho_reshaped,\n",
    "                      X_falff_reshaped], axis = -1)\n",
    "\n",
    "y_combined = y_FC\n",
    "X_combined.shape\n",
    "\n",
    "X_pheno = pheno_data.drop(columns = \"DX\").values\n",
    "scaler = StandardScaler()\n",
    "X_pheno = scaler.fit_transform(X_pheno) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5c9aa-6e81-4724-89fb-be1d588f9bd0",
   "metadata": {},
   "source": [
    "### Building the multi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf987abe-c9fb-42cd-a04f-1eb026a4f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # CNN Branch\n",
    "    cnn_input = Input(shape=(190, 190, 3), name=\"cnn_input\")\n",
    "    \n",
    "    x = Conv2D(\n",
    "        filters=hp.Choice('conv1_filters', [32, 64]),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )(cnn_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=hp.Choice('conv2_filters', [64, 96, 128]),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=hp.Choice('conv3_filters', [128, 256]),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Instead of Flatten immediately\n",
    "    gap = GlobalAveragePooling2D()(x)             # shape (batch, channels)\n",
    "    attention = Dense(gap.shape[-1], activation='sigmoid')(gap)\n",
    "    attention = Reshape((1, 1, gap.shape[-1]))(attention)\n",
    "    x = Multiply()([x, attention])                # Broadcast attention over spatial dimensions\n",
    "       \n",
    "    #x = Flatten()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # MLP Branch\n",
    "    mlp_input = Input(shape=(6,), name=\"mlp_input\")\n",
    "\n",
    "    y = Dense(\n",
    "        units=hp.Int('mlp_units1', 32, 128, step=32),\n",
    "        activation='relu'\n",
    "    )(mlp_input)\n",
    "    y = Dropout(hp.Float('mlp_dropout', 0.3, 0.7, step=0.1))(y)\n",
    "\n",
    "    y = Dense(\n",
    "        units=hp.Int('mlp_units2', 16, 64, step=16),\n",
    "        activation='relu'\n",
    "    )(y)\n",
    "\n",
    "    # Merge branches\n",
    "    merged = concatenate([x, y])\n",
    "\n",
    "    z = Dense(\n",
    "        units=hp.Int('dense_units', 64, 256, step=64),\n",
    "        activation='relu'\n",
    "    )(merged)\n",
    "    z = Dropout(hp.Float('final_dropout', 0.3, 0.7, step=0.1))(z)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input], outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-3, 5e-4, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65006796-9fa9-4999-950d-cdb9fd31fd73",
   "metadata": {},
   "source": [
    "### Splitting Data and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2d181b4-86d4-47ab-964e-dba1c1590f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 20s]\n",
      "val_accuracy: 0.7777777910232544\n",
      "\n",
      "Best val_accuracy So Far: 0.7979797720909119\n",
      "Total elapsed time: 00h 03m 20s\n",
      "\n",
      "Best Hyperparameters:\n",
      "conv1_filters: 64\n",
      "conv2_filters: 128\n",
      "conv3_filters: 128\n",
      "mlp_units1: 96\n",
      "mlp_dropout: 0.3\n",
      "mlp_units2: 32\n",
      "dense_units: 256\n",
      "final_dropout: 0.5\n",
      "lr: 0.001\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 2s 106ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.7861 - val_accuracy: 0.5455\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0270 - accuracy: 0.9975 - val_loss: 0.5847 - val_accuracy: 0.7677\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.6768\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.6087 - val_accuracy: 0.7677\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 3.3051 - val_accuracy: 0.4444\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0248 - accuracy: 0.9949 - val_loss: 4.9412 - val_accuracy: 0.4444\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 2.1048 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2a208700>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step\n",
      "\n",
      "Validation Accuracy: 0.6667\n",
      "Validation F1 Score: 0.6658\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7619    0.5818    0.6598        55\n",
      "           1     0.5965    0.7727    0.6733        44\n",
      "\n",
      "    accuracy                         0.6667        99\n",
      "   macro avg     0.6792    0.6773    0.6665        99\n",
      "weighted avg     0.6884    0.6667    0.6658        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- Step 0: Split Data ---\n",
    "X_cnn = X_combined               # shape: (n_samples, 190, 190, 3)\n",
    "X_mlp = X_pheno                  # standardized phenotypic features\n",
    "y = y_FC                         # binary target\n",
    "\n",
    "X_cnn_train, X_cnn_val, X_mlp_train, X_mlp_val, y_train, y_val = train_test_split(\n",
    "    X_cnn, X_mlp, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 1: Define Hyperparameter Tuner ---\n",
    "tuner = RandomSearch(\n",
    "    build_model,                              # your model function\n",
    "    objective='val_accuracy',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_multimodal',\n",
    "    project_name='cnn_mlp_combo',\n",
    "    overwrite=True                           # <== important to allow fresh rerun\n",
    ")\n",
    "\n",
    "# --- Step 2: Run Tuning ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    [X_cnn_train, X_mlp_train], y_train,\n",
    "    validation_data=([X_cnn_val, X_mlp_val], y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Step 3: Retrieve Best Model ---\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for key in best_hp.values:\n",
    "    print(f\"{key}: {best_hp.get(key)}\")\n",
    "\n",
    "# --- Step 4: Evaluate or Retrain ---\n",
    "#class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "#class_weight_dict = {i: class_weights_array[i] for i in range(len(class_weights_array))}\n",
    "class_weight_dict = {0: 1.0, 1: 1.5}\n",
    "#class_weight_dict = {0: 1.0, 1: 2.0}\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    [X_cnn_train, X_mlp_train], y_train,\n",
    "    validation_data=([X_cnn_val, X_mlp_val], y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Step 5: Final Evaluation ---\n",
    "#y_pred = (best_model.predict([X_cnn_val, X_mlp_val]) > 0.5).astype(int)\n",
    "y_pred_probs = best_model.predict([X_cnn_val, X_mlp_val])\n",
    "y_pred = (y_pred_probs > 0.4).astype(int)  \n",
    "\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nValidation Accuracy: {acc:.4f}\")\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "# Save to results\n",
    "results.append({\n",
    "    'Dataset': 'CNN with Attention + MLP',\n",
    "    'Best Params': {key: best_hp.get(key) for key in best_hp.values},\n",
    "    'Val Accuracy': acc,\n",
    "    'Val F1': f1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3a95a-72d0-486f-a9ac-52b8209c22c5",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd3032c3-b0c4-4f34-a41d-f7ee084c418d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 4s 199ms/step - loss: 0.9860 - accuracy: 0.4695 - val_loss: 0.6425 - val_accuracy: 0.7800\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.8626 - accuracy: 0.5824 - val_loss: 0.5859 - val_accuracy: 0.7600\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7384 - accuracy: 0.6817 - val_loss: 0.5777 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6280 - accuracy: 0.7652 - val_loss: 0.5239 - val_accuracy: 0.8400\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5401 - accuracy: 0.8375 - val_loss: 0.4883 - val_accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4419 - accuracy: 0.8555 - val_loss: 0.5441 - val_accuracy: 0.5200\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.3312 - accuracy: 0.9052 - val_loss: 0.4679 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2130 - accuracy: 0.9436 - val_loss: 0.4645 - val_accuracy: 0.8600\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1448 - accuracy: 0.9526 - val_loss: 0.4172 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1329 - accuracy: 0.9865 - val_loss: 0.4334 - val_accuracy: 0.8200\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0998 - accuracy: 0.9752 - val_loss: 0.3545 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0508 - accuracy: 0.9977 - val_loss: 0.3362 - val_accuracy: 0.8800\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0419 - accuracy: 0.9955 - val_loss: 0.3367 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.3187 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9200\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8800\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.8600\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.8600\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8600\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 1 Accuracy: 0.8400 | F1 Score: 0.8390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7143    0.8333        28\n",
      "           1     0.7333    1.0000    0.8462        22\n",
      "\n",
      "    accuracy                         0.8400        50\n",
      "   macro avg     0.8667    0.8571    0.8397        50\n",
      "weighted avg     0.8827    0.8400    0.8390        50\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 1.0020 - accuracy: 0.4808 - val_loss: 0.7053 - val_accuracy: 0.4400\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.8635 - accuracy: 0.5688 - val_loss: 0.6534 - val_accuracy: 0.4400\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7704 - accuracy: 0.6637 - val_loss: 0.5814 - val_accuracy: 0.7400\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6699 - accuracy: 0.7517 - val_loss: 0.5412 - val_accuracy: 0.7400\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5780 - accuracy: 0.8307 - val_loss: 0.4964 - val_accuracy: 0.8400\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5343 - accuracy: 0.8330 - val_loss: 0.4572 - val_accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3794 - accuracy: 0.9142 - val_loss: 0.4429 - val_accuracy: 0.8400\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3182 - accuracy: 0.9165 - val_loss: 0.4374 - val_accuracy: 0.7800\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1846 - accuracy: 0.9549 - val_loss: 0.4348 - val_accuracy: 0.7800\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1208 - accuracy: 0.9729 - val_loss: 0.3973 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1373 - accuracy: 0.9684 - val_loss: 0.4981 - val_accuracy: 0.7600\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0880 - accuracy: 0.9819 - val_loss: 0.5336 - val_accuracy: 0.6800\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0786 - accuracy: 0.9819 - val_loss: 0.4469 - val_accuracy: 0.7400\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0546 - accuracy: 0.9865 - val_loss: 0.3792 - val_accuracy: 0.8200\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0342 - accuracy: 0.9932 - val_loss: 0.8528 - val_accuracy: 0.5200\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0285 - accuracy: 0.9977 - val_loss: 0.5079 - val_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0358 - accuracy: 0.9932 - val_loss: 0.4457 - val_accuracy: 0.7800\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.5113 - val_accuracy: 0.4400\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.0180 - accuracy: 0.9977 - val_loss: 0.7324 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Fold 2 Accuracy: 0.8200 | F1 Score: 0.8195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.7143    0.8163        28\n",
      "           1     0.7241    0.9545    0.8235        22\n",
      "\n",
      "    accuracy                         0.8200        50\n",
      "   macro avg     0.8383    0.8344    0.8199        50\n",
      "weighted avg     0.8520    0.8200    0.8195        50\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 3s 114ms/step - loss: 0.9874 - accuracy: 0.5034 - val_loss: 0.6987 - val_accuracy: 0.4400\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.8721 - accuracy: 0.5576 - val_loss: 0.5964 - val_accuracy: 0.7600\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.7208 - accuracy: 0.7133 - val_loss: 0.5517 - val_accuracy: 0.7800\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6565 - accuracy: 0.7404 - val_loss: 0.5618 - val_accuracy: 0.7600\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5773 - accuracy: 0.7968 - val_loss: 0.5732 - val_accuracy: 0.7400\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5022 - accuracy: 0.8330 - val_loss: 0.5500 - val_accuracy: 0.7600\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.4097 - accuracy: 0.8804 - val_loss: 0.5625 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.3474 - accuracy: 0.8804 - val_loss: 0.5526 - val_accuracy: 0.7600\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2228 - accuracy: 0.9323 - val_loss: 0.5100 - val_accuracy: 0.7800\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2232 - accuracy: 0.9368 - val_loss: 0.5078 - val_accuracy: 0.7600\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1130 - accuracy: 0.9752 - val_loss: 0.4632 - val_accuracy: 0.8600\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.0832 - accuracy: 0.9774 - val_loss: 0.5268 - val_accuracy: 0.7800\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.7800\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0242 - accuracy: 0.9977 - val_loss: 0.9646 - val_accuracy: 0.7400\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.0393 - accuracy: 0.9932 - val_loss: 1.0160 - val_accuracy: 0.7400\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 1.7493 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 3 Accuracy: 0.7800 | F1 Score: 0.7808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8400    0.7500    0.7925        28\n",
      "           1     0.7200    0.8182    0.7660        22\n",
      "\n",
      "    accuracy                         0.7800        50\n",
      "   macro avg     0.7800    0.7841    0.7792        50\n",
      "weighted avg     0.7872    0.7800    0.7808        50\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 4s 199ms/step - loss: 0.9402 - accuracy: 0.5090 - val_loss: 0.6279 - val_accuracy: 0.7347\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7598 - accuracy: 0.6892 - val_loss: 0.6446 - val_accuracy: 0.4490\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6396 - accuracy: 0.7635 - val_loss: 0.5124 - val_accuracy: 0.7959\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5546 - accuracy: 0.8086 - val_loss: 0.5873 - val_accuracy: 0.6327\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4523 - accuracy: 0.8514 - val_loss: 0.5874 - val_accuracy: 0.6327\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.3249 - accuracy: 0.9167 - val_loss: 0.5268 - val_accuracy: 0.7959\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2473 - accuracy: 0.9437 - val_loss: 0.6753 - val_accuracy: 0.4898\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2344 - accuracy: 0.9437 - val_loss: 0.6110 - val_accuracy: 0.6327\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Fold 4 Accuracy: 0.8163 | F1 Score: 0.8149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.6786    0.8085        28\n",
      "           1     0.7000    1.0000    0.8235        21\n",
      "\n",
      "    accuracy                         0.8163        49\n",
      "   macro avg     0.8500    0.8393    0.8160        49\n",
      "weighted avg     0.8714    0.8163    0.8149        49\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 0.9705 - accuracy: 0.5135 - val_loss: 0.6620 - val_accuracy: 0.7347\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.8368 - accuracy: 0.5473 - val_loss: 0.6076 - val_accuracy: 0.7551\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7087 - accuracy: 0.7590 - val_loss: 0.5780 - val_accuracy: 0.7755\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6220 - accuracy: 0.7635 - val_loss: 0.5434 - val_accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5621 - accuracy: 0.8153 - val_loss: 0.5325 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4496 - accuracy: 0.8739 - val_loss: 0.5260 - val_accuracy: 0.7959\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3644 - accuracy: 0.8829 - val_loss: 0.5329 - val_accuracy: 0.7755\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2723 - accuracy: 0.9347 - val_loss: 0.5304 - val_accuracy: 0.7551\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1949 - accuracy: 0.9392 - val_loss: 0.5754 - val_accuracy: 0.7959\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1838 - accuracy: 0.9369 - val_loss: 0.5637 - val_accuracy: 0.8163\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1443 - accuracy: 0.9662 - val_loss: 0.6378 - val_accuracy: 0.7347\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Fold 5 Accuracy: 0.8367 | F1 Score: 0.8371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9545    0.7500    0.8400        28\n",
      "           1     0.7407    0.9524    0.8333        21\n",
      "\n",
      "    accuracy                         0.8367        49\n",
      "   macro avg     0.8476    0.8512    0.8367        49\n",
      "weighted avg     0.8629    0.8367    0.8371        49\n",
      "\n",
      "\n",
      "Fold 6\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 1.0071 - accuracy: 0.4640 - val_loss: 0.7105 - val_accuracy: 0.4286\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.8237 - accuracy: 0.6171 - val_loss: 0.6367 - val_accuracy: 0.6939\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.7076 - accuracy: 0.7117 - val_loss: 0.6210 - val_accuracy: 0.7143\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.6036 - accuracy: 0.8041 - val_loss: 0.6214 - val_accuracy: 0.6939\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.5402 - accuracy: 0.8198 - val_loss: 0.6180 - val_accuracy: 0.6939\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.4363 - accuracy: 0.8581 - val_loss: 0.6026 - val_accuracy: 0.6939\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3959 - accuracy: 0.8739 - val_loss: 0.6466 - val_accuracy: 0.6939\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4019 - accuracy: 0.8784 - val_loss: 0.6122 - val_accuracy: 0.6939\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2534 - accuracy: 0.9189 - val_loss: 0.6811 - val_accuracy: 0.6939\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1774 - accuracy: 0.9640 - val_loss: 0.9847 - val_accuracy: 0.6327\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1108 - accuracy: 0.9820 - val_loss: 0.9581 - val_accuracy: 0.6735\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 6 Accuracy: 0.7551 | F1 Score: 0.7545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.6667    0.7500        27\n",
      "           1     0.6786    0.8636    0.7600        22\n",
      "\n",
      "    accuracy                         0.7551        49\n",
      "   macro avg     0.7679    0.7652    0.7550        49\n",
      "weighted avg     0.7770    0.7551    0.7545        49\n",
      "\n",
      "\n",
      "Fold 7\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 102ms/step - loss: 0.9616 - accuracy: 0.5068 - val_loss: 0.6965 - val_accuracy: 0.4490\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.8320 - accuracy: 0.6486 - val_loss: 0.6510 - val_accuracy: 0.4694\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7050 - accuracy: 0.6937 - val_loss: 0.5841 - val_accuracy: 0.7959\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.6466 - accuracy: 0.7635 - val_loss: 0.6448 - val_accuracy: 0.5510\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5417 - accuracy: 0.8086 - val_loss: 0.6599 - val_accuracy: 0.5510\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5018 - accuracy: 0.8401 - val_loss: 0.6058 - val_accuracy: 0.6735\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4781 - accuracy: 0.8243 - val_loss: 0.6649 - val_accuracy: 0.5510\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3755 - accuracy: 0.8829 - val_loss: 0.7399 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 7 Accuracy: 0.7755 | F1 Score: 0.7742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.6667    0.7660        27\n",
      "           1     0.6897    0.9091    0.7843        22\n",
      "\n",
      "    accuracy                         0.7755        49\n",
      "   macro avg     0.7948    0.7879    0.7751        49\n",
      "weighted avg     0.8056    0.7755    0.7742        49\n",
      "\n",
      "\n",
      "Fold 8\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 0.9245 - accuracy: 0.5315 - val_loss: 0.6739 - val_accuracy: 0.4490\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7979 - accuracy: 0.6486 - val_loss: 0.5827 - val_accuracy: 0.7143\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6691 - accuracy: 0.7095 - val_loss: 0.5678 - val_accuracy: 0.6939\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6185 - accuracy: 0.7928 - val_loss: 0.5395 - val_accuracy: 0.7551\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5409 - accuracy: 0.8311 - val_loss: 0.5488 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4922 - accuracy: 0.8401 - val_loss: 0.5278 - val_accuracy: 0.7755\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3356 - accuracy: 0.9009 - val_loss: 0.5006 - val_accuracy: 0.7347\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2571 - accuracy: 0.9347 - val_loss: 0.4942 - val_accuracy: 0.7755\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2008 - accuracy: 0.9324 - val_loss: 0.4648 - val_accuracy: 0.7143\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1253 - accuracy: 0.9775 - val_loss: 0.4691 - val_accuracy: 0.7959\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1468 - accuracy: 0.9572 - val_loss: 0.4555 - val_accuracy: 0.6939\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1071 - accuracy: 0.9775 - val_loss: 0.4440 - val_accuracy: 0.7347\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0459 - accuracy: 0.9910 - val_loss: 0.4426 - val_accuracy: 0.7347\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1165 - accuracy: 0.9617 - val_loss: 0.5811 - val_accuracy: 0.7755\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0546 - accuracy: 0.9887 - val_loss: 0.5332 - val_accuracy: 0.7755\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0673 - accuracy: 0.9865 - val_loss: 0.6515 - val_accuracy: 0.7551\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0838 - accuracy: 0.9797 - val_loss: 0.5274 - val_accuracy: 0.7755\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0402 - accuracy: 0.9932 - val_loss: 0.4907 - val_accuracy: 0.7755\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 8 Accuracy: 0.7959 | F1 Score: 0.7916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.6296    0.7727        27\n",
      "           1     0.6875    1.0000    0.8148        22\n",
      "\n",
      "    accuracy                         0.7959        49\n",
      "   macro avg     0.8438    0.8148    0.7938        49\n",
      "weighted avg     0.8597    0.7959    0.7916        49\n",
      "\n",
      "\n",
      "Fold 9\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 0.9876 - accuracy: 0.5270 - val_loss: 0.6343 - val_accuracy: 0.7551\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.8625 - accuracy: 0.5518 - val_loss: 0.6686 - val_accuracy: 0.4490\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7637 - accuracy: 0.6937 - val_loss: 0.5503 - val_accuracy: 0.7347\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6637 - accuracy: 0.7613 - val_loss: 0.5753 - val_accuracy: 0.8163\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5923 - accuracy: 0.7793 - val_loss: 0.5457 - val_accuracy: 0.7959\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5554 - accuracy: 0.8041 - val_loss: 0.5318 - val_accuracy: 0.7959\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4337 - accuracy: 0.8626 - val_loss: 0.5654 - val_accuracy: 0.7959\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.3439 - accuracy: 0.9122 - val_loss: 0.5886 - val_accuracy: 0.7143\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2589 - accuracy: 0.9212 - val_loss: 0.4863 - val_accuracy: 0.8163\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2089 - accuracy: 0.9550 - val_loss: 0.4911 - val_accuracy: 0.7959\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1106 - accuracy: 0.9707 - val_loss: 0.6549 - val_accuracy: 0.7143\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0660 - accuracy: 0.9865 - val_loss: 0.7728 - val_accuracy: 0.6531\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0336 - accuracy: 0.9977 - val_loss: 1.4031 - val_accuracy: 0.5510\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.6327\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 9 Accuracy: 0.8367 | F1 Score: 0.8370\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9130    0.7778    0.8400        27\n",
      "           1     0.7692    0.9091    0.8333        22\n",
      "\n",
      "    accuracy                         0.8367        49\n",
      "   macro avg     0.8411    0.8434    0.8367        49\n",
      "weighted avg     0.8485    0.8367    0.8370        49\n",
      "\n",
      "\n",
      "Fold 10\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 0.9565 - accuracy: 0.5495 - val_loss: 0.6616 - val_accuracy: 0.7143\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.8166 - accuracy: 0.6194 - val_loss: 0.6227 - val_accuracy: 0.7347\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.7105 - accuracy: 0.7185 - val_loss: 0.6052 - val_accuracy: 0.7143\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6074 - accuracy: 0.7725 - val_loss: 0.5982 - val_accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5123 - accuracy: 0.8333 - val_loss: 0.5892 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4276 - accuracy: 0.8514 - val_loss: 0.5806 - val_accuracy: 0.7347\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.3568 - accuracy: 0.8761 - val_loss: 0.6088 - val_accuracy: 0.6122\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1787 - accuracy: 0.9572 - val_loss: 0.6177 - val_accuracy: 0.6122\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1135 - accuracy: 0.9775 - val_loss: 0.6423 - val_accuracy: 0.5918\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1093 - accuracy: 0.9752 - val_loss: 0.5808 - val_accuracy: 0.7551\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1562 - accuracy: 0.9482 - val_loss: 0.5501 - val_accuracy: 0.7959\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1359 - accuracy: 0.9707 - val_loss: 0.6843 - val_accuracy: 0.5306\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0401 - accuracy: 0.9955 - val_loss: 0.8489 - val_accuracy: 0.4490\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.0244 - accuracy: 0.9955 - val_loss: 0.6608 - val_accuracy: 0.6735\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.6939\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.0154 - accuracy: 0.9977 - val_loss: 1.1146 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 10 Accuracy: 0.8776 | F1 Score: 0.8778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.8148    0.8800        27\n",
      "           1     0.8077    0.9545    0.8750        22\n",
      "\n",
      "    accuracy                         0.8776        49\n",
      "   macro avg     0.8821    0.8847    0.8775        49\n",
      "weighted avg     0.8897    0.8776    0.8778        49\n",
      "\n",
      "\n",
      "Average CV Accuracy: 0.8134\n",
      "Average CV F1 Score: 0.8126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_combined, y_FC)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    X_cnn_train, X_cnn_val = X_combined[train_idx], X_combined[val_idx]\n",
    "    X_mlp_train, X_mlp_val = X_pheno[train_idx], X_pheno[val_idx]\n",
    "    y_train, y_val = y_FC[train_idx], y_FC[val_idx]\n",
    "\n",
    "    # Compute class weights\n",
    "    #class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    #class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    #for w in [1.0, 1.5, 2.0, 3.0]:\n",
    "        #class_weight_dict = {0: 1.0, 1: w}\n",
    "    #class_weight_dict = {0: 1.0, 1: 1.5}\n",
    "    class_weight_dict = {0: 1.0, 1: 2.0}\n",
    "\n",
    "    # Build model with best hyperparameters\n",
    "    model = build_model(best_hp)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        [X_cnn_train, X_mlp_train], y_train,\n",
    "        validation_data=([X_cnn_val, X_mlp_val], y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate model\n",
    "    # y_pred = (model.predict([X_cnn_val, X_mlp_val]) > 0.5).astype(int)\n",
    "    y_pred_probs = best_model.predict([X_cnn_val, X_mlp_val])\n",
    "    y_pred = (y_pred_probs > 0.4).astype(int)  \n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Fold {fold + 1} Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_f1_scores.append(f1)\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nAverage CV Accuracy: {np.mean(cv_accuracies):.4f}\")\n",
    "print(f\"Average CV F1 Score: {np.mean(cv_f1_scores):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Dataset': 'Multimodal CNN + MLP (CV + Attention + Tuned)',\n",
    "    'Val Accuracy': np.mean(cv_accuracies),\n",
    "    'Val F1': np.mean(cv_f1_scores),\n",
    "    'Best Params': {key: best_hp.get(key) for key in best_hp.values}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a78c5-27c1-417a-87b5-ea3b23928ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a1f63a2-98a0-4f8a-bacd-c7915f62ddc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 3s 125ms/step - loss: 1.0221 - accuracy: 0.5085 - val_loss: 0.6728 - val_accuracy: 0.4500\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.9292 - accuracy: 0.5141 - val_loss: 0.6572 - val_accuracy: 0.4500\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8296 - accuracy: 0.7006 - val_loss: 0.5479 - val_accuracy: 0.7750\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.7187 - accuracy: 0.6610 - val_loss: 0.5044 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6486 - accuracy: 0.7797 - val_loss: 0.5517 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6131 - accuracy: 0.7458 - val_loss: 0.5452 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5567 - accuracy: 0.8023 - val_loss: 0.5066 - val_accuracy: 0.8250\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5460 - accuracy: 0.8390 - val_loss: 0.4514 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5153 - accuracy: 0.8023 - val_loss: 0.4707 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.3603 - accuracy: 0.8955 - val_loss: 0.4182 - val_accuracy: 0.8500\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3136 - accuracy: 0.9209 - val_loss: 0.6174 - val_accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2792 - accuracy: 0.9040 - val_loss: 0.8791 - val_accuracy: 0.5500\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2982 - accuracy: 0.9124 - val_loss: 0.6176 - val_accuracy: 0.7250\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2229 - accuracy: 0.9294 - val_loss: 1.1959 - val_accuracy: 0.5500\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1569 - accuracy: 0.9633 - val_loss: 1.7924 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd22ea7c10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 1 Accuracy: 0.8250 | F1 Score: 0.8159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7586    1.0000    0.8627        22\n",
      "           1     1.0000    0.6111    0.7586        18\n",
      "\n",
      "    accuracy                         0.8250        40\n",
      "   macro avg     0.8793    0.8056    0.8107        40\n",
      "weighted avg     0.8672    0.8250    0.8159        40\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 100ms/step - loss: 1.0074 - accuracy: 0.4774 - val_loss: 0.6757 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.8829 - accuracy: 0.5989 - val_loss: 0.6741 - val_accuracy: 0.4500\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.7715 - accuracy: 0.6695 - val_loss: 0.7164 - val_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6537 - accuracy: 0.7260 - val_loss: 0.6661 - val_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6242 - accuracy: 0.7994 - val_loss: 0.6283 - val_accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5408 - accuracy: 0.7881 - val_loss: 0.6662 - val_accuracy: 0.4500\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4624 - accuracy: 0.8616 - val_loss: 0.6914 - val_accuracy: 0.4250\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4280 - accuracy: 0.8785 - val_loss: 0.7713 - val_accuracy: 0.4500\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3163 - accuracy: 0.9153 - val_loss: 0.8514 - val_accuracy: 0.4500\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2600 - accuracy: 0.9068 - val_loss: 0.9895 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2c65e470>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 2 Accuracy: 0.7500 | F1 Score: 0.7335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.9545    0.8077        22\n",
      "           1     0.9000    0.5000    0.6429        18\n",
      "\n",
      "    accuracy                         0.7500        40\n",
      "   macro avg     0.8000    0.7273    0.7253        40\n",
      "weighted avg     0.7900    0.7500    0.7335        40\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 3s 105ms/step - loss: 0.9977 - accuracy: 0.4548 - val_loss: 0.6260 - val_accuracy: 0.7000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.8401 - accuracy: 0.5113 - val_loss: 0.5945 - val_accuracy: 0.5500\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.8025 - accuracy: 0.7881 - val_loss: 0.5325 - val_accuracy: 0.7250\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6656 - accuracy: 0.7062 - val_loss: 0.5071 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6006 - accuracy: 0.7966 - val_loss: 0.5114 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5605 - accuracy: 0.8023 - val_loss: 0.5010 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5259 - accuracy: 0.8107 - val_loss: 0.4789 - val_accuracy: 0.8250\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4858 - accuracy: 0.8503 - val_loss: 0.4642 - val_accuracy: 0.8250\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.3944 - accuracy: 0.9068 - val_loss: 0.4861 - val_accuracy: 0.8250\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.3702 - accuracy: 0.8814 - val_loss: 0.4962 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.2883 - accuracy: 0.9237 - val_loss: 0.4620 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.3165 - accuracy: 0.9379 - val_loss: 0.4468 - val_accuracy: 0.8250\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.2230 - accuracy: 0.9435 - val_loss: 0.4613 - val_accuracy: 0.8250\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1818 - accuracy: 0.9492 - val_loss: 0.4722 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1020 - accuracy: 0.9944 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0729 - accuracy: 0.9887 - val_loss: 0.5381 - val_accuracy: 0.8250\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0313 - accuracy: 0.9972 - val_loss: 0.5036 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd30b8ff10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 3 Accuracy: 0.8250 | F1 Score: 0.8198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7778    0.9545    0.8571        22\n",
      "           1     0.9231    0.6667    0.7742        18\n",
      "\n",
      "    accuracy                         0.8250        40\n",
      "   macro avg     0.8504    0.8106    0.8157        40\n",
      "weighted avg     0.8432    0.8250    0.8198        40\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 98ms/step - loss: 0.9896 - accuracy: 0.4915 - val_loss: 0.6672 - val_accuracy: 0.7000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8775 - accuracy: 0.4972 - val_loss: 0.6393 - val_accuracy: 0.5750\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8010 - accuracy: 0.7175 - val_loss: 0.6352 - val_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.7164 - accuracy: 0.6638 - val_loss: 0.6368 - val_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6900 - accuracy: 0.8107 - val_loss: 0.6739 - val_accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6521 - accuracy: 0.6864 - val_loss: 0.6255 - val_accuracy: 0.4500\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5586 - accuracy: 0.8305 - val_loss: 0.6484 - val_accuracy: 0.4500\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4891 - accuracy: 0.8559 - val_loss: 0.6436 - val_accuracy: 0.4500\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4444 - accuracy: 0.8644 - val_loss: 0.7553 - val_accuracy: 0.4500\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3959 - accuracy: 0.8644 - val_loss: 0.6271 - val_accuracy: 0.5250\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2726 - accuracy: 0.9350 - val_loss: 0.6131 - val_accuracy: 0.5500\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3247 - accuracy: 0.9011 - val_loss: 0.8121 - val_accuracy: 0.4500\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1752 - accuracy: 0.9605 - val_loss: 0.5017 - val_accuracy: 0.7000\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1516 - accuracy: 0.9633 - val_loss: 0.7446 - val_accuracy: 0.5250\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1262 - accuracy: 0.9774 - val_loss: 0.4762 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2683 - accuracy: 0.9435 - val_loss: 0.9855 - val_accuracy: 0.4750\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1400 - accuracy: 0.9633 - val_loss: 0.9283 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0685 - accuracy: 0.9859 - val_loss: 1.1189 - val_accuracy: 0.4500\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.9474 - val_accuracy: 0.4500\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0357 - accuracy: 0.9972 - val_loss: 1.0027 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd29d3aa10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 4 Accuracy: 0.8000 | F1 Score: 0.7868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7333    1.0000    0.8462        22\n",
      "           1     1.0000    0.5556    0.7143        18\n",
      "\n",
      "    accuracy                         0.8000        40\n",
      "   macro avg     0.8667    0.7778    0.7802        40\n",
      "weighted avg     0.8533    0.8000    0.7868        40\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 119ms/step - loss: 0.9373 - accuracy: 0.5014 - val_loss: 0.6674 - val_accuracy: 0.4359\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8357 - accuracy: 0.5775 - val_loss: 0.6221 - val_accuracy: 0.7436\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.7288 - accuracy: 0.7070 - val_loss: 0.5819 - val_accuracy: 0.7949\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6216 - accuracy: 0.7972 - val_loss: 0.5707 - val_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5861 - accuracy: 0.7972 - val_loss: 0.5574 - val_accuracy: 0.7692\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5180 - accuracy: 0.8310 - val_loss: 0.5497 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4834 - accuracy: 0.8338 - val_loss: 0.5397 - val_accuracy: 0.7692\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4048 - accuracy: 0.8845 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3415 - accuracy: 0.9014 - val_loss: 0.5543 - val_accuracy: 0.7949\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2396 - accuracy: 0.9577 - val_loss: 0.6249 - val_accuracy: 0.6154\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1871 - accuracy: 0.9549 - val_loss: 0.8270 - val_accuracy: 0.4359\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.1290 - accuracy: 0.9831 - val_loss: 0.6295 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd22987eb0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 5 Accuracy: 0.7692 | F1 Score: 0.7552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7241    0.9545    0.8235        22\n",
      "           1     0.9000    0.5294    0.6667        17\n",
      "\n",
      "    accuracy                         0.7692        39\n",
      "   macro avg     0.8121    0.7420    0.7451        39\n",
      "weighted avg     0.8008    0.7692    0.7552        39\n",
      "\n",
      "\n",
      "Fold 6\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 99ms/step - loss: 0.9818 - accuracy: 0.4986 - val_loss: 0.6806 - val_accuracy: 0.4615\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8889 - accuracy: 0.4873 - val_loss: 0.6586 - val_accuracy: 0.4615\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.8073 - accuracy: 0.6028 - val_loss: 0.6181 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6740 - accuracy: 0.6930 - val_loss: 0.6101 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6179 - accuracy: 0.7803 - val_loss: 0.5966 - val_accuracy: 0.7179\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5511 - accuracy: 0.8141 - val_loss: 0.5840 - val_accuracy: 0.7179\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5016 - accuracy: 0.8254 - val_loss: 0.5873 - val_accuracy: 0.7179\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4291 - accuracy: 0.8535 - val_loss: 0.5681 - val_accuracy: 0.7179\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.3593 - accuracy: 0.9070 - val_loss: 0.5543 - val_accuracy: 0.7179\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2719 - accuracy: 0.9183 - val_loss: 0.5494 - val_accuracy: 0.7179\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2050 - accuracy: 0.9549 - val_loss: 0.6004 - val_accuracy: 0.7179\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1435 - accuracy: 0.9718 - val_loss: 0.5318 - val_accuracy: 0.7179\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1235 - accuracy: 0.9718 - val_loss: 0.5487 - val_accuracy: 0.7179\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.1203 - accuracy: 0.9662 - val_loss: 0.5296 - val_accuracy: 0.7436\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0725 - accuracy: 0.9803 - val_loss: 1.1964 - val_accuracy: 0.6410\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0595 - accuracy: 0.9944 - val_loss: 0.5409 - val_accuracy: 0.7179\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0543 - accuracy: 0.9887 - val_loss: 0.6493 - val_accuracy: 0.7179\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0812 - accuracy: 0.9746 - val_loss: 0.5490 - val_accuracy: 0.7179\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.1369 - accuracy: 0.9521 - val_loss: 0.6013 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2d4b96c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 6 Accuracy: 0.7179 | F1 Score: 0.6911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6774    0.9545    0.7925        22\n",
      "           1     0.8750    0.4118    0.5600        17\n",
      "\n",
      "    accuracy                         0.7179        39\n",
      "   macro avg     0.7762    0.6832    0.6762        39\n",
      "weighted avg     0.7635    0.7179    0.6911        39\n",
      "\n",
      "\n",
      "Fold 7\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 98ms/step - loss: 1.0070 - accuracy: 0.4761 - val_loss: 0.7217 - val_accuracy: 0.4359\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.8451 - accuracy: 0.5746 - val_loss: 0.6867 - val_accuracy: 0.4359\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.7244 - accuracy: 0.6507 - val_loss: 0.5482 - val_accuracy: 0.7179\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6753 - accuracy: 0.7775 - val_loss: 0.4815 - val_accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5959 - accuracy: 0.8141 - val_loss: 0.4282 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5390 - accuracy: 0.8423 - val_loss: 0.3999 - val_accuracy: 0.8718\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4773 - accuracy: 0.8366 - val_loss: 0.3806 - val_accuracy: 0.8718\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4682 - accuracy: 0.8310 - val_loss: 0.3886 - val_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4025 - accuracy: 0.8563 - val_loss: 0.3632 - val_accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3634 - accuracy: 0.9042 - val_loss: 0.3653 - val_accuracy: 0.8718\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4108 - accuracy: 0.8451 - val_loss: 0.4015 - val_accuracy: 0.8462\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.3065 - accuracy: 0.9324 - val_loss: 0.3402 - val_accuracy: 0.8974\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2635 - accuracy: 0.9437 - val_loss: 0.3612 - val_accuracy: 0.8718\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1723 - accuracy: 0.9634 - val_loss: 0.3619 - val_accuracy: 0.8718\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1420 - accuracy: 0.9775 - val_loss: 0.3359 - val_accuracy: 0.8974\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0996 - accuracy: 0.9831 - val_loss: 0.3365 - val_accuracy: 0.8718\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0678 - accuracy: 0.9944 - val_loss: 0.4102 - val_accuracy: 0.8718\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0442 - accuracy: 0.9972 - val_loss: 0.7735 - val_accuracy: 0.4359\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0308 - accuracy: 0.9944 - val_loss: 1.0188 - val_accuracy: 0.4103\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 1.3293 - val_accuracy: 0.4359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2d4bbf10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 7 Accuracy: 0.8718 | F1 Score: 0.8673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8148    1.0000    0.8980        22\n",
      "           1     1.0000    0.7059    0.8276        17\n",
      "\n",
      "    accuracy                         0.8718        39\n",
      "   macro avg     0.9074    0.8529    0.8628        39\n",
      "weighted avg     0.8955    0.8718    0.8673        39\n",
      "\n",
      "\n",
      "Fold 8\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 98ms/step - loss: 0.9836 - accuracy: 0.4901 - val_loss: 0.6354 - val_accuracy: 0.7436\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.8098 - accuracy: 0.5915 - val_loss: 0.5913 - val_accuracy: 0.7692\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.7201 - accuracy: 0.7155 - val_loss: 0.5818 - val_accuracy: 0.7692\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6359 - accuracy: 0.7944 - val_loss: 0.5788 - val_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6212 - accuracy: 0.7521 - val_loss: 0.5698 - val_accuracy: 0.7949\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5529 - accuracy: 0.8282 - val_loss: 0.5354 - val_accuracy: 0.7692\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4384 - accuracy: 0.8648 - val_loss: 0.5352 - val_accuracy: 0.7692\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4141 - accuracy: 0.8958 - val_loss: 0.5171 - val_accuracy: 0.7692\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3819 - accuracy: 0.8845 - val_loss: 0.5276 - val_accuracy: 0.7692\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3167 - accuracy: 0.9211 - val_loss: 0.5199 - val_accuracy: 0.7179\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1777 - accuracy: 0.9634 - val_loss: 0.5359 - val_accuracy: 0.7692\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.1623 - accuracy: 0.9662 - val_loss: 0.5117 - val_accuracy: 0.7692\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0785 - accuracy: 0.9859 - val_loss: 0.5408 - val_accuracy: 0.7436\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0518 - accuracy: 0.9944 - val_loss: 0.5001 - val_accuracy: 0.7692\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0707 - accuracy: 0.9859 - val_loss: 0.6006 - val_accuracy: 0.6410\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0986 - accuracy: 0.9746 - val_loss: 0.5470 - val_accuracy: 0.7692\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.6832 - val_accuracy: 0.7692\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0352 - accuracy: 0.9944 - val_loss: 0.5165 - val_accuracy: 0.7692\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0583 - accuracy: 0.9859 - val_loss: 0.5026 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2ec0fb20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 8 Accuracy: 0.7692 | F1 Score: 0.7552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7241    0.9545    0.8235        22\n",
      "           1     0.9000    0.5294    0.6667        17\n",
      "\n",
      "    accuracy                         0.7692        39\n",
      "   macro avg     0.8121    0.7420    0.7451        39\n",
      "weighted avg     0.8008    0.7692    0.7552        39\n",
      "\n",
      "\n",
      "Fold 9\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 98ms/step - loss: 1.0205 - accuracy: 0.5099 - val_loss: 0.7434 - val_accuracy: 0.4359\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.8914 - accuracy: 0.4986 - val_loss: 0.6671 - val_accuracy: 0.4359\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.7675 - accuracy: 0.6958 - val_loss: 0.6034 - val_accuracy: 0.7179\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6731 - accuracy: 0.7521 - val_loss: 0.6129 - val_accuracy: 0.7179\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5850 - accuracy: 0.7493 - val_loss: 0.5859 - val_accuracy: 0.7692\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5788 - accuracy: 0.8366 - val_loss: 0.5634 - val_accuracy: 0.7436\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4529 - accuracy: 0.8423 - val_loss: 0.5563 - val_accuracy: 0.7436\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.3975 - accuracy: 0.8761 - val_loss: 0.5438 - val_accuracy: 0.7692\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2886 - accuracy: 0.9239 - val_loss: 0.5258 - val_accuracy: 0.7179\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1817 - accuracy: 0.9690 - val_loss: 0.5221 - val_accuracy: 0.7179\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5156 - accuracy: 0.7690 - val_loss: 0.5616 - val_accuracy: 0.7179\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3817 - accuracy: 0.8845 - val_loss: 0.6748 - val_accuracy: 0.7179\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.3140 - accuracy: 0.8958 - val_loss: 0.5695 - val_accuracy: 0.7179\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.2198 - accuracy: 0.9493 - val_loss: 0.9124 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1589 - accuracy: 0.9521 - val_loss: 1.4588 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2f3fa080>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "Fold 9 Accuracy: 0.7179 | F1 Score: 0.6787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    1.0000    0.8000        22\n",
      "           1     1.0000    0.3529    0.5217        17\n",
      "\n",
      "    accuracy                         0.7179        39\n",
      "   macro avg     0.8333    0.6765    0.6609        39\n",
      "weighted avg     0.8120    0.7179    0.6787        39\n",
      "\n",
      "\n",
      "Fold 10\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 100ms/step - loss: 0.9443 - accuracy: 0.5042 - val_loss: 0.6690 - val_accuracy: 0.4359\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.8216 - accuracy: 0.5803 - val_loss: 0.6435 - val_accuracy: 0.4615\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.7335 - accuracy: 0.7690 - val_loss: 0.5934 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6740 - accuracy: 0.6451 - val_loss: 0.5503 - val_accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6221 - accuracy: 0.8113 - val_loss: 0.5868 - val_accuracy: 0.6410\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5676 - accuracy: 0.7831 - val_loss: 0.5846 - val_accuracy: 0.6154\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4836 - accuracy: 0.8620 - val_loss: 0.5896 - val_accuracy: 0.6154\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4691 - accuracy: 0.8338 - val_loss: 0.5340 - val_accuracy: 0.7949\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.3747 - accuracy: 0.9070 - val_loss: 0.5871 - val_accuracy: 0.6154\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.2528 - accuracy: 0.9465 - val_loss: 0.7064 - val_accuracy: 0.4615\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1957 - accuracy: 0.9549 - val_loss: 0.5191 - val_accuracy: 0.8718\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.2119 - accuracy: 0.9239 - val_loss: 0.5047 - val_accuracy: 0.8462\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0942 - accuracy: 0.9915 - val_loss: 0.6142 - val_accuracy: 0.7436\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1275 - accuracy: 0.9718 - val_loss: 0.4676 - val_accuracy: 0.8205\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0723 - accuracy: 0.9859 - val_loss: 2.9956 - val_accuracy: 0.5641\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.1058 - accuracy: 0.9803 - val_loss: 1.4741 - val_accuracy: 0.6154\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0780 - accuracy: 0.9775 - val_loss: 0.6454 - val_accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0748 - accuracy: 0.9887 - val_loss: 1.7157 - val_accuracy: 0.5641\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0437 - accuracy: 0.9915 - val_loss: 1.4396 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd2cf834c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step\n",
      "Fold 10 Accuracy: 0.7692 | F1 Score: 0.7552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7241    0.9545    0.8235        22\n",
      "           1     0.9000    0.5294    0.6667        17\n",
      "\n",
      "    accuracy                         0.7692        39\n",
      "   macro avg     0.8121    0.7420    0.7451        39\n",
      "weighted avg     0.8008    0.7692    0.7552        39\n",
      "\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "\n",
      "Hold-Out Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7222    0.9455    0.8189        55\n",
      "           1     0.8889    0.5455    0.6761        44\n",
      "\n",
      "    accuracy                         0.7677        99\n",
      "   macro avg     0.8056    0.7455    0.7475        99\n",
      "weighted avg     0.7963    0.7677    0.7554        99\n",
      "\n",
      "\n",
      "Average CV Accuracy: 0.7815\n",
      "Average CV F1 Score: 0.7659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Split off 20% test set\n",
    "X_train_img, X_test_img, X_train_pheno, X_test_pheno, y_train_all, y_test = train_test_split(\n",
    "    X_combined, X_pheno, y_FC, test_size=0.2, stratify=y_FC, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Perform 10-fold CV on training set\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracies, cv_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_img, y_train_all)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "    X_cnn_train, X_cnn_val = X_train_img[train_idx], X_train_img[val_idx]\n",
    "    X_mlp_train, X_mlp_val = X_train_pheno[train_idx], X_train_pheno[val_idx]\n",
    "    y_train, y_val = y_train_all[train_idx], y_train_all[val_idx]\n",
    "\n",
    "    # Class weights\n",
    "    class_weight_dict = {0: 1, 1: 2}\n",
    "    #class_weight_dict = {0: 1.0, 1: 2.0}\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_model(best_hp)\n",
    "    model.fit(\n",
    "        [X_cnn_train, X_mlp_train], y_train,\n",
    "        validation_data=([X_cnn_val, X_mlp_val], y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on validation fold\n",
    "    y_pred_probs = model.predict([X_cnn_val, X_mlp_val])\n",
    "    y_pred = (y_pred_probs > 0.7).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Fold {fold + 1} Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_f1_scores.append(f1)\n",
    "\n",
    "# Step 3: Evaluate final model on hold-out test set\n",
    "y_test_probs = model.predict([X_test_img, X_test_pheno])\n",
    "y_test_pred = (y_test_probs > 0.7).astype(int)\n",
    "\n",
    "print(\"\\nHold-Out Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# Step 4: Final CV results summary\n",
    "print(f\"\\nAverage CV Accuracy: {np.mean(cv_accuracies):.4f}\")\n",
    "print(f\"Average CV F1 Score: {np.mean(cv_f1_scores):.4f}\")\n",
    "\n",
    "# Step 5: Save to results list\n",
    "results.append({\n",
    "    'Dataset': 'Multimodal CNN + MLP (CV + Attention + Tuned)',\n",
    "    'Val Accuracy': np.mean(cv_accuracies),\n",
    "    'Val F1': np.mean(cv_f1_scores),\n",
    "    'Best Params': {key: best_hp.get(key) for key in best_hp.values}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb5f23-51c4-4446-b49b-a4284ec5492b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "466897a3-7f9a-4321-8600-940a31c927ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "{0: 220, 1: 174}\n",
      "\n",
      "Test set class distribution:\n",
      "{0: 55, 1: 44}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "unique_train, counts_train = np.unique(y_train_all, return_counts=True)\n",
    "print(dict(zip(unique_train, counts_train)))\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique_test, counts_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baae82-a843-4c2c-93b6-060cd4601271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
