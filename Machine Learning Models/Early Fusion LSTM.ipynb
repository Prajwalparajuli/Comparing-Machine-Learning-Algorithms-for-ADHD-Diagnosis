{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a379756-19c8-4d49-9252-e9bda4b159fa",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c859b32-4e64-4cf8-bfd3-47c95516adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set global seed\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7354e07-f87c-494f-ae4e-f690c9eb28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First subject ID: 1018959\n",
      "Shape of X_rnn: (620, 260, 190)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/rnn_dataset_with_subjects.npz\")\n",
    "X_rnn = data[\"X\"]\n",
    "y_labels = data[\"y\"]\n",
    "subject_ids = data[\"subject_ids\"]\n",
    "\n",
    "print(\"First subject ID:\", subject_ids[0])\n",
    "print(\"Shape of X_rnn:\", X_rnn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fb9e0-24b1-4dff-9d6e-919da3aea03c",
   "metadata": {},
   "source": [
    "## Loading the phenotypic data to merge with ltsm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce9196b-6f01-4889-9199-24afe0f10121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inattentive</th>\n",
       "      <th>Hyper/Impulsive</th>\n",
       "      <th>Verbal IQ</th>\n",
       "      <th>Performance IQ</th>\n",
       "      <th>Full4 IQ</th>\n",
       "      <th>Med Status</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018959</th>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019436</th>\n",
       "      <td>60.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043241</th>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266183</th>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535233</th>\n",
       "      <td>41.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669389</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383713</th>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477085</th>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994085</th>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191384</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Inattentive  Hyper/Impulsive  Verbal IQ  Performance IQ  Full4 IQ  \\\n",
       "Subject ID                                                                      \n",
       "1018959            47.0             44.0       99.0           115.0     103.0   \n",
       "1019436            60.0             66.0      124.0           108.0     122.0   \n",
       "1043241            40.0             43.0      128.0           106.0     120.0   \n",
       "1266183            44.0             43.0      136.0            96.0     120.0   \n",
       "1535233            41.0             43.0      106.0           135.0     122.0   \n",
       "...                 ...              ...        ...             ...       ...   \n",
       "5669389            15.0              9.0      120.0            97.0     110.0   \n",
       "6383713            29.0             32.0      115.0            91.0     104.0   \n",
       "6477085            13.0             12.0      115.0           112.0     115.0   \n",
       "7994085            23.0             15.0       89.0            86.0      86.0   \n",
       "8191384            11.0             10.0      104.0            81.0      92.0   \n",
       "\n",
       "            Med Status  DX  \n",
       "Subject ID                  \n",
       "1018959              1   0  \n",
       "1019436              1   1  \n",
       "1043241              1   0  \n",
       "1266183              1   0  \n",
       "1535233              1   0  \n",
       "...                ...  ..  \n",
       "5669389              1   0  \n",
       "6383713              1   1  \n",
       "6477085              1   0  \n",
       "7994085              1   0  \n",
       "8191384              1   0  \n",
       "\n",
       "[493 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "FC_pheno_data = pd.read_csv(\"C:/Users/prajw/Desktop/Undergrad Research/Datasets/Preprocessed FC matrix with Pheno/FC_Merged.csv\", index_col = 0)\n",
    "FC_pheno_data.index.name = \"Subject ID\"\n",
    "\n",
    "phenotype_cols = ['Inattentive', 'Hyper/Impulsive', 'Verbal IQ', \n",
    "                  'Performance IQ', 'Full4 IQ', 'Med Status', 'DX']\n",
    "pheno_data = FC_pheno_data[phenotype_cols].copy()\n",
    "pheno_data.index.name = 'Subject ID'\n",
    "pheno_data['DX'] = pheno_data['DX'].apply(lambda x: 1 if x > 0 else 0)\n",
    "pheno_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b778c7-1a03-4374-bc90-9efbf6922b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched subjects: 493\n",
      "X_rnn_matched shape: (493, 260, 190)\n",
      "X_pheno_scaled shape: (493, 6)\n",
      "y_labels_matched shape: (493,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure subject_ids and pheno_data index are both zero-padded strings\n",
    "subject_ids = np.array([str(sid).zfill(7) for sid in subject_ids])\n",
    "pheno_data.index = pheno_data.index.astype(str).str.zfill(7)\n",
    "\n",
    "# Now match properly\n",
    "matching_ids = [sid for sid in subject_ids if sid in pheno_data.index]\n",
    "print(f\"Matched subjects: {len(matching_ids)}\")  # Should now be ~493\n",
    "\n",
    "# Get indices of matching IDs from full list\n",
    "matching_indices = [np.where(subject_ids == sid)[0][0] for sid in matching_ids]\n",
    "\n",
    "# Subset data accordingly\n",
    "X_rnn_matched = X_rnn[matching_indices]\n",
    "y_labels_matched = y_labels[matching_indices]\n",
    "\n",
    "phenotype_cols = ['Inattentive', 'Hyper/Impulsive', 'Verbal IQ', \n",
    "                  'Performance IQ', 'Full4 IQ', 'Med Status']\n",
    "pheno_subset = pheno_data.loc[matching_ids, phenotype_cols].fillna(0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_pheno_scaled = scaler.fit_transform(pheno_subset)\n",
    "\n",
    "# Final checks\n",
    "print(\"X_rnn_matched shape:\", X_rnn_matched.shape)\n",
    "print(\"X_pheno_scaled shape:\", X_pheno_scaled.shape)\n",
    "print(\"y_labels_matched shape:\", y_labels_matched.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd6a040-146a-487e-84f0-47d83113505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (fMRI): (394, 260, 190)\n",
      "Test shape (fMRI): (99, 260, 190)\n",
      "Train shape (pheno): (394, 6)\n",
      "Test shape (pheno): (99, 6)\n",
      "y_train_all shape: (394,)\n",
      "y_test shape: (99,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_ts_train, X_ts_test, X_pheno_train, X_pheno_test, y_train_all, y_test = train_test_split(\n",
    "    X_rnn_matched, X_pheno_scaled, y_labels_matched,\n",
    "    test_size=0.2,\n",
    "    stratify=y_labels_matched,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape (fMRI):\", X_ts_train.shape)\n",
    "print(\"Test shape (fMRI):\", X_ts_test.shape)\n",
    "print(\"Train shape (pheno):\", X_pheno_train.shape)\n",
    "print(\"Test shape (pheno):\", X_pheno_test.shape)\n",
    "print(\"y_train_all shape:\", y_train_all.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bda8dd4-939d-4c28-bd67-c2e74b92a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Masking, LSTM, Dense, Dropout, concatenate, RepeatVector, Attention, Concatenate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Build early fusion LSTM model\n",
    "def build_early_fusion_model(ts_shape=(260, 190), pheno_dim=6):\n",
    "    input_ts = Input(shape=ts_shape)                            # (260, 190)\n",
    "    input_pheno = Input(shape=(pheno_dim,))                     # (6,)\n",
    "\n",
    "    x_ts = Masking(mask_value=0.0)(input_ts)\n",
    "\n",
    "    # Repeat phenotype features to match time steps (260,)\n",
    "    x_pheno = RepeatVector(ts_shape[0])(input_pheno)            # (260, 6)\n",
    "\n",
    "    # Concatenate along last axis: (260, 190+6)\n",
    "    fused_input = Concatenate(axis=-1)([x_ts, x_pheno])\n",
    "\n",
    "    # LSTM layers\n",
    "    x = LSTM(64, return_sequences=True)(fused_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention_scores = Dense(1, activation='tanh')(x)\n",
    "    attention_weights = tf.nn.softmax(attention_scores, axis=1)\n",
    "    context_vector = tf.reduce_sum(attention_weights * x, axis=1)\n",
    "\n",
    "    # Dense output layers\n",
    "    x = Dense(32, activation='relu')(context_vector)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input_ts, input_pheno], outputs=output)\n",
    "    model.compile(optimizer=RMSprop(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f15edd3-e309-4a72-8862-c866bdd45774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "2/2 [==============================] - 3s 39ms/step\n",
      "Accuracy: 0.5500, Precision: 0.5000, Recall: 0.3333, F1: 0.4000\n",
      "\n",
      "Fold 2\n",
      "2/2 [==============================] - 2s 42ms/step\n",
      "Accuracy: 0.5750, Precision: 1.0000, Recall: 0.0556, F1: 0.1053\n",
      "\n",
      "Fold 3\n",
      "2/2 [==============================] - 2s 29ms/step\n",
      "Accuracy: 0.5000, Precision: 0.4167, Recall: 0.2778, F1: 0.3333\n",
      "\n",
      "Fold 4\n",
      "2/2 [==============================] - 2s 42ms/step\n",
      "Accuracy: 0.5000, Precision: 0.4583, Recall: 0.6111, F1: 0.5238\n",
      "\n",
      "Fold 5\n",
      "2/2 [==============================] - 2s 38ms/step\n",
      "Accuracy: 0.5385, Precision: 0.4545, Recall: 0.2941, F1: 0.3571\n",
      "\n",
      "Fold 6\n",
      "2/2 [==============================] - 3s 37ms/step\n",
      "Accuracy: 0.4872, Precision: 0.4516, Recall: 0.8235, F1: 0.5833\n",
      "\n",
      "Fold 7\n",
      "2/2 [==============================] - 3s 37ms/step\n",
      "Accuracy: 0.5385, Precision: 0.3333, Recall: 0.0588, F1: 0.1000\n",
      "\n",
      "Fold 8\n",
      "2/2 [==============================] - 3s 40ms/step\n",
      "Accuracy: 0.5385, Precision: 0.4783, Recall: 0.6471, F1: 0.5500\n",
      "\n",
      "Fold 9\n",
      "2/2 [==============================] - 3s 39ms/step\n",
      "Accuracy: 0.5128, Precision: 0.3333, Recall: 0.1176, F1: 0.1739\n",
      "\n",
      "Fold 10\n",
      "2/2 [==============================] - 3s 35ms/step\n",
      "Accuracy: 0.3590, Precision: 0.3667, Recall: 0.6471, F1: 0.4681\n",
      "\n",
      "Cross-Validation Summary:\n",
      "Avg Accuracy:  0.5099\n",
      "Avg Precision: 0.4793\n",
      "Avg Recall:    0.3866\n",
      "Avg F1-score:  0.3595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_labels_matched), y=y_labels_matched)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Step 2: Use only training data for CV\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "all_acc, all_prec, all_recall, all_f1 = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(y_train_all, y_train_all), start=1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    \n",
    "    X_cv_train_ts, X_cv_val_ts = X_train_ts[train_idx], X_train_ts[val_idx]\n",
    "    X_cv_train_pheno, X_cv_val_pheno = X_train_pheno[train_idx], X_train_pheno[val_idx]\n",
    "    y_cv_train, y_cv_val = y_train_all[train_idx], y_train_all[val_idx]\n",
    "\n",
    "    model = build_early_fusion_model()\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        [X_cv_train_ts, X_cv_train_pheno], y_cv_train,\n",
    "        validation_data=([X_cv_val_ts, X_cv_val_pheno], y_cv_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred_probs = model.predict([X_cv_val_ts, X_cv_val_pheno])\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Evaluation\n",
    "    acc = accuracy_score(y_cv_val, y_pred)\n",
    "    prec = precision_score(y_cv_val, y_pred)\n",
    "    recall = recall_score(y_cv_val, y_pred)\n",
    "    f1 = f1_score(y_cv_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_prec.append(prec)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(f\"Avg Accuracy:  {np.mean(all_acc):.4f}\")\n",
    "print(f\"Avg Precision: {np.mean(all_prec):.4f}\")\n",
    "print(f\"Avg Recall:    {np.mean(all_recall):.4f}\")\n",
    "print(f\"Avg F1-score:  {np.mean(all_f1):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bbc2569-2da9-40f9-8ccf-3b98d9a5ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 45ms/step\n",
      "\n",
      "Hold-Out Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.27      0.11      0.16        55\n",
      "        ADHD       0.36      0.64      0.46        44\n",
      "\n",
      "    accuracy                           0.34        99\n",
      "   macro avg       0.32      0.37      0.31        99\n",
      "weighted avg       0.31      0.34      0.29        99\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6 49]\n",
      " [16 28]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on aligned test set\n",
    "y_test_probs = model.predict([X_ts_test, X_pheno_test])\n",
    "y_test_pred = (y_test_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nHold-Out Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Control\", \"ADHD\"]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaf4ae-4f73-4665-a08e-34b0592c2e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74d3a8d7-c34a-40c1-bb1b-a485f023aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Masking, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# LSTM model using only time series data\n",
    "def build_lstm_model(ts_shape=(260, 190)):\n",
    "    input_ts = Input(shape=ts_shape)               # Only time series input\n",
    "\n",
    "    x = Masking(mask_value=0.0)(input_ts)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention_scores = Dense(1, activation='tanh')(x)\n",
    "    attention_weights = tf.nn.softmax(attention_scores, axis=1)\n",
    "    context_vector = tf.reduce_sum(attention_weights * x, axis=1)\n",
    "\n",
    "    x = Dense(32, activation='relu')(context_vector)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_ts, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "811dd80b-6db5-422e-a2a9-19bdef09b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use matched arrays with phenotype data (after alignment)\n",
    "X_train_ts, X_test_ts, y_train_all, y_test = train_test_split(\n",
    "    X_rnn_matched, y_labels_matched, test_size=0.2, stratify=y_labels_matched, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48b7b79a-c09d-469f-b24d-6764b9285963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "2/2 [==============================] - 2s 27ms/step\n",
      "Accuracy: 0.6000, Precision: 0.5417, Recall: 0.7222, F1: 0.6190\n",
      "\n",
      "Fold 2\n",
      "2/2 [==============================] - 2s 41ms/step\n",
      "Accuracy: 0.6000, Precision: 0.5556, Recall: 0.5556, F1: 0.5556\n",
      "\n",
      "Fold 3\n",
      "2/2 [==============================] - 2s 33ms/step\n",
      "Accuracy: 0.6500, Precision: 0.5909, Recall: 0.7222, F1: 0.6500\n",
      "\n",
      "Fold 4\n",
      "2/2 [==============================] - 3s 49ms/step\n",
      "Accuracy: 0.5500, Precision: 0.5000, Recall: 0.5556, F1: 0.5263\n",
      "\n",
      "Fold 5\n",
      "2/2 [==============================] - 2s 41ms/step\n",
      "Accuracy: 0.5641, Precision: 0.5000, Recall: 0.4118, F1: 0.4516\n",
      "\n",
      "Fold 6\n",
      "2/2 [==============================] - 2s 36ms/step\n",
      "Accuracy: 0.6410, Precision: 0.6000, Recall: 0.5294, F1: 0.5625\n",
      "\n",
      "Fold 7\n",
      "2/2 [==============================] - 2s 45ms/step\n",
      "Accuracy: 0.6410, Precision: 0.5714, Recall: 0.7059, F1: 0.6316\n",
      "\n",
      "Fold 8\n",
      "2/2 [==============================] - 2s 34ms/step\n",
      "Accuracy: 0.5897, Precision: 0.5333, Recall: 0.4706, F1: 0.5000\n",
      "\n",
      "Fold 9\n",
      "2/2 [==============================] - 3s 40ms/step\n",
      "Accuracy: 0.5641, Precision: 0.5000, Recall: 0.6471, F1: 0.5641\n",
      "\n",
      "Fold 10\n",
      "2/2 [==============================] - 3s 54ms/step\n",
      "Accuracy: 0.6154, Precision: 0.5500, Recall: 0.6471, F1: 0.5946\n",
      "\n",
      "Cross-Validation Summary:\n",
      "Avg Accuracy:  0.6015\n",
      "Avg Precision: 0.5443\n",
      "Avg Recall:    0.5967\n",
      "Avg F1-score:  0.5655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_all), y=y_train_all)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 10-fold CV\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "all_acc, all_prec, all_recall, all_f1 = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_ts, y_train_all), start=1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_cv_train_ts, X_cv_val_ts = X_train_ts[train_idx], X_train_ts[val_idx]\n",
    "    y_cv_train, y_cv_val = y_train_all[train_idx], y_train_all[val_idx]\n",
    "\n",
    "    model = build_lstm_model()\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_cv_train_ts, y_cv_train,\n",
    "        validation_data=(X_cv_val_ts, y_cv_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred_probs = model.predict(X_cv_val_ts)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "    acc = accuracy_score(y_cv_val, y_pred)\n",
    "    prec = precision_score(y_cv_val, y_pred)\n",
    "    recall = recall_score(y_cv_val, y_pred)\n",
    "    f1 = f1_score(y_cv_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_prec.append(prec)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(f\"Avg Accuracy:  {np.mean(all_acc):.4f}\")\n",
    "print(f\"Avg Precision: {np.mean(all_prec):.4f}\")\n",
    "print(f\"Avg Recall:    {np.mean(all_recall):.4f}\")\n",
    "print(f\"Avg F1-score:  {np.mean(all_f1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db3853f7-c8f6-413c-8dc1-dd5b95e687e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 51ms/step\n",
      "\n",
      "Hold-Out Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.60      0.53      0.56        55\n",
      "        ADHD       0.49      0.57      0.53        44\n",
      "\n",
      "    accuracy                           0.55        99\n",
      "   macro avg       0.55      0.55      0.54        99\n",
      "weighted avg       0.55      0.55      0.55        99\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29 26]\n",
      " [19 25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on hold-out test set\n",
    "y_test_probs = model.predict(X_test_ts)\n",
    "y_test_pred = (y_test_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nHold-Out Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Control\", \"ADHD\"]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0ff80-28f7-4bd9-a991-934c34d0086b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ac6e6ae-2da8-4380-b439-03fced3747bc",
   "metadata": {},
   "source": [
    "## Merging the pheno with time series acorss the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3149ed6-3317-4cf2-9cb0-79090f5cce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pheno_tiled shape: (493, 260, 6)\n"
     ]
    }
   ],
   "source": [
    "# Repeat phenotypic features for each time step (260) per subject\n",
    "X_pheno_tiled = np.repeat(X_pheno_scaled[:, np.newaxis, :], repeats=260, axis=1)\n",
    "\n",
    "print(\"X_pheno_tiled shape:\", X_pheno_tiled.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ba67ab0-6f5b-4e65-8756-bf737193e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape: (493, 260, 196)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along the last axis (feature dimension)\n",
    "X_combined = np.concatenate([X_rnn_matched, X_pheno_tiled], axis=-1)\n",
    "\n",
    "print(\"X_combined shape:\", X_combined.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a4ae1-c9ca-4f30-8bb4-228da6774488",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "406c2409-671c-4191-8483-8d93445e71cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (394, 260, 196)\n",
      "Test shape:  (99, 260, 196)\n",
      "y_train shape: (394,), y_test shape: (99,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80/20 stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y_labels_matched,\n",
    "    test_size=0.2,\n",
    "    stratify=y_labels_matched,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape:  {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775a7ad-7a28-4480-b47c-d98ec8fa6219",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f43cf98-7122-43c6-9e36-c546faf89efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_fused_lstm_model(input_shape=(260, 196)):\n",
    "    input_layer = Input(shape=input_shape)  # (time_steps=260, features=196)\n",
    "    \n",
    "    x = Masking(mask_value=0.0)(input_layer)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention\n",
    "    attention_scores = Dense(1, activation='tanh')(x)\n",
    "    attention_weights = tf.nn.softmax(attention_scores, axis=1)\n",
    "    context_vector = tf.reduce_sum(attention_weights * x, axis=1)\n",
    "    \n",
    "    x = Dense(32, activation='relu')(context_vector)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1ae3a-1dcf-4d59-811b-6cd6d966e36a",
   "metadata": {},
   "source": [
    "## Cross Validation to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18ba8998-74c5-4470-b9e6-03d6fdb33fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 310ms/step - loss: 0.6875 - accuracy: 0.6158 - val_loss: 0.6812 - val_accuracy: 0.7000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6750 - accuracy: 0.7316 - val_loss: 0.6718 - val_accuracy: 0.7750\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6677 - accuracy: 0.7260 - val_loss: 0.6626 - val_accuracy: 0.7750\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6583 - accuracy: 0.7655 - val_loss: 0.6558 - val_accuracy: 0.7750\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.6512 - accuracy: 0.7599 - val_loss: 0.6483 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6460 - accuracy: 0.7740 - val_loss: 0.6407 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6326 - accuracy: 0.7825 - val_loss: 0.6302 - val_accuracy: 0.8250\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6248 - accuracy: 0.7825 - val_loss: 0.6202 - val_accuracy: 0.8250\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6174 - accuracy: 0.7768 - val_loss: 0.6079 - val_accuracy: 0.8250\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6026 - accuracy: 0.7938 - val_loss: 0.5954 - val_accuracy: 0.8250\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.5901 - accuracy: 0.8107 - val_loss: 0.5804 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.5802 - accuracy: 0.8164 - val_loss: 0.5638 - val_accuracy: 0.8250\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.5626 - accuracy: 0.7994 - val_loss: 0.5456 - val_accuracy: 0.8250\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5529 - accuracy: 0.8079 - val_loss: 0.5284 - val_accuracy: 0.8500\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5341 - accuracy: 0.8249 - val_loss: 0.5108 - val_accuracy: 0.8500\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5182 - accuracy: 0.8277 - val_loss: 0.4915 - val_accuracy: 0.8500\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5079 - accuracy: 0.8305 - val_loss: 0.4728 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4879 - accuracy: 0.8333 - val_loss: 0.4517 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4680 - accuracy: 0.8503 - val_loss: 0.4282 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4540 - accuracy: 0.8588 - val_loss: 0.4070 - val_accuracy: 0.9250\n",
      "2/2 [==============================] - 2s 33ms/step\n",
      "Accuracy: 0.9250, Precision: 1.0000, Recall: 0.8333, F1: 0.9091\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 325ms/step - loss: 0.6809 - accuracy: 0.5819 - val_loss: 0.6728 - val_accuracy: 0.6750\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.6620 - accuracy: 0.7458 - val_loss: 0.6623 - val_accuracy: 0.7250\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6526 - accuracy: 0.7571 - val_loss: 0.6530 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6393 - accuracy: 0.7853 - val_loss: 0.6439 - val_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6264 - accuracy: 0.7910 - val_loss: 0.6316 - val_accuracy: 0.7000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6091 - accuracy: 0.8079 - val_loss: 0.6236 - val_accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.6017 - accuracy: 0.8192 - val_loss: 0.6146 - val_accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5884 - accuracy: 0.8051 - val_loss: 0.6040 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5728 - accuracy: 0.8249 - val_loss: 0.5979 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5644 - accuracy: 0.8192 - val_loss: 0.5898 - val_accuracy: 0.7250\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5497 - accuracy: 0.8249 - val_loss: 0.5837 - val_accuracy: 0.7250\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5399 - accuracy: 0.8531 - val_loss: 0.5785 - val_accuracy: 0.7250\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5259 - accuracy: 0.8390 - val_loss: 0.5760 - val_accuracy: 0.7250\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5157 - accuracy: 0.8503 - val_loss: 0.5719 - val_accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5068 - accuracy: 0.8559 - val_loss: 0.5733 - val_accuracy: 0.7250\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4957 - accuracy: 0.8672 - val_loss: 0.5732 - val_accuracy: 0.7250\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.4849 - accuracy: 0.8814 - val_loss: 0.5701 - val_accuracy: 0.7250\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.4719 - accuracy: 0.8729 - val_loss: 0.5652 - val_accuracy: 0.7250\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4624 - accuracy: 0.8842 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.4424 - accuracy: 0.8983 - val_loss: 0.5507 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 3s 47ms/step\n",
      "Accuracy: 0.7750, Precision: 0.8000, Recall: 0.6667, F1: 0.7273\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 15s 322ms/step - loss: 0.6816 - accuracy: 0.6215 - val_loss: 0.6630 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.6677 - accuracy: 0.6977 - val_loss: 0.6515 - val_accuracy: 0.8250\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6576 - accuracy: 0.7740 - val_loss: 0.6365 - val_accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6430 - accuracy: 0.7825 - val_loss: 0.6221 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.6345 - accuracy: 0.7910 - val_loss: 0.6070 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.6192 - accuracy: 0.7825 - val_loss: 0.5909 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6028 - accuracy: 0.7910 - val_loss: 0.5757 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5910 - accuracy: 0.7938 - val_loss: 0.5587 - val_accuracy: 0.8250\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.5768 - accuracy: 0.8023 - val_loss: 0.5458 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5674 - accuracy: 0.8023 - val_loss: 0.5334 - val_accuracy: 0.8500\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5525 - accuracy: 0.7910 - val_loss: 0.5194 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5415 - accuracy: 0.8023 - val_loss: 0.5041 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5213 - accuracy: 0.8192 - val_loss: 0.4908 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5111 - accuracy: 0.8305 - val_loss: 0.4801 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4940 - accuracy: 0.8475 - val_loss: 0.4677 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.4845 - accuracy: 0.8446 - val_loss: 0.4579 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.4767 - accuracy: 0.8418 - val_loss: 0.4501 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4615 - accuracy: 0.8531 - val_loss: 0.4386 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.4489 - accuracy: 0.8616 - val_loss: 0.4343 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.4423 - accuracy: 0.8644 - val_loss: 0.4192 - val_accuracy: 0.8750\n",
      "2/2 [==============================] - 2s 47ms/step\n",
      "Accuracy: 0.8750, Precision: 0.9333, Recall: 0.7778, F1: 0.8485\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 11s 299ms/step - loss: 0.6822 - accuracy: 0.6836 - val_loss: 0.6806 - val_accuracy: 0.7000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.6713 - accuracy: 0.7401 - val_loss: 0.6734 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.6615 - accuracy: 0.7684 - val_loss: 0.6651 - val_accuracy: 0.7250\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6545 - accuracy: 0.7571 - val_loss: 0.6569 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6446 - accuracy: 0.7655 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6333 - accuracy: 0.7486 - val_loss: 0.6402 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6250 - accuracy: 0.7514 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6089 - accuracy: 0.7825 - val_loss: 0.6216 - val_accuracy: 0.7250\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5982 - accuracy: 0.7740 - val_loss: 0.6078 - val_accuracy: 0.7250\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5767 - accuracy: 0.7910 - val_loss: 0.5963 - val_accuracy: 0.7250\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.5600 - accuracy: 0.7910 - val_loss: 0.5864 - val_accuracy: 0.7250\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5491 - accuracy: 0.8023 - val_loss: 0.5761 - val_accuracy: 0.7250\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.5285 - accuracy: 0.7966 - val_loss: 0.5669 - val_accuracy: 0.7250\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.5179 - accuracy: 0.8192 - val_loss: 0.5564 - val_accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.5064 - accuracy: 0.8051 - val_loss: 0.5507 - val_accuracy: 0.7250\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.4956 - accuracy: 0.8220 - val_loss: 0.5408 - val_accuracy: 0.7250\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.4759 - accuracy: 0.8418 - val_loss: 0.5310 - val_accuracy: 0.7250\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.4569 - accuracy: 0.8475 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.4357 - accuracy: 0.8588 - val_loss: 0.5116 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4256 - accuracy: 0.8672 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 3s 26ms/step\n",
      "Accuracy: 0.8000, Precision: 0.9167, Recall: 0.6111, F1: 0.7333\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 311ms/step - loss: 0.6863 - accuracy: 0.6535 - val_loss: 0.6797 - val_accuracy: 0.7436\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6708 - accuracy: 0.7606 - val_loss: 0.6675 - val_accuracy: 0.7436\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.6602 - accuracy: 0.7606 - val_loss: 0.6535 - val_accuracy: 0.7692\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.6484 - accuracy: 0.7718 - val_loss: 0.6390 - val_accuracy: 0.7949\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6338 - accuracy: 0.7718 - val_loss: 0.6223 - val_accuracy: 0.7949\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6181 - accuracy: 0.7803 - val_loss: 0.6072 - val_accuracy: 0.7949\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6017 - accuracy: 0.7859 - val_loss: 0.5937 - val_accuracy: 0.7949\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5890 - accuracy: 0.7915 - val_loss: 0.5801 - val_accuracy: 0.7949\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5733 - accuracy: 0.7972 - val_loss: 0.5639 - val_accuracy: 0.7949\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.5556 - accuracy: 0.7944 - val_loss: 0.5502 - val_accuracy: 0.7949\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.5388 - accuracy: 0.7915 - val_loss: 0.5339 - val_accuracy: 0.7949\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5203 - accuracy: 0.8000 - val_loss: 0.5200 - val_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5129 - accuracy: 0.7944 - val_loss: 0.5093 - val_accuracy: 0.7949\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.4999 - accuracy: 0.7944 - val_loss: 0.4987 - val_accuracy: 0.7949\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4882 - accuracy: 0.8000 - val_loss: 0.4901 - val_accuracy: 0.7949\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4758 - accuracy: 0.8028 - val_loss: 0.4838 - val_accuracy: 0.7949\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.4585 - accuracy: 0.8085 - val_loss: 0.4758 - val_accuracy: 0.7949\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4486 - accuracy: 0.8310 - val_loss: 0.4701 - val_accuracy: 0.7949\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.4355 - accuracy: 0.8366 - val_loss: 0.4632 - val_accuracy: 0.7949\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.4117 - accuracy: 0.8563 - val_loss: 0.4585 - val_accuracy: 0.7949\n",
      "2/2 [==============================] - 3s 32ms/step\n",
      "Accuracy: 0.7949, Precision: 0.9091, Recall: 0.5882, F1: 0.7143\n",
      "\n",
      "Fold 6\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 316ms/step - loss: 0.6910 - accuracy: 0.5183 - val_loss: 0.6890 - val_accuracy: 0.5641\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6847 - accuracy: 0.5972 - val_loss: 0.6819 - val_accuracy: 0.6410\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6745 - accuracy: 0.7014 - val_loss: 0.6754 - val_accuracy: 0.6154\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6659 - accuracy: 0.7296 - val_loss: 0.6670 - val_accuracy: 0.6154\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6536 - accuracy: 0.7493 - val_loss: 0.6557 - val_accuracy: 0.5897\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6443 - accuracy: 0.7634 - val_loss: 0.6439 - val_accuracy: 0.6410\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6251 - accuracy: 0.7972 - val_loss: 0.6320 - val_accuracy: 0.7436\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6119 - accuracy: 0.7915 - val_loss: 0.6185 - val_accuracy: 0.7692\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5970 - accuracy: 0.8197 - val_loss: 0.6037 - val_accuracy: 0.7949\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5779 - accuracy: 0.8085 - val_loss: 0.5879 - val_accuracy: 0.8205\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5585 - accuracy: 0.8225 - val_loss: 0.5728 - val_accuracy: 0.8462\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5457 - accuracy: 0.8338 - val_loss: 0.5605 - val_accuracy: 0.8462\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5267 - accuracy: 0.8423 - val_loss: 0.5489 - val_accuracy: 0.8462\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5168 - accuracy: 0.8535 - val_loss: 0.5382 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5015 - accuracy: 0.8592 - val_loss: 0.5256 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4866 - accuracy: 0.8676 - val_loss: 0.5120 - val_accuracy: 0.8974\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4716 - accuracy: 0.8620 - val_loss: 0.4987 - val_accuracy: 0.8718\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4503 - accuracy: 0.8958 - val_loss: 0.4782 - val_accuracy: 0.8974\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4245 - accuracy: 0.9014 - val_loss: 0.4635 - val_accuracy: 0.8718\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4004 - accuracy: 0.9239 - val_loss: 0.4469 - val_accuracy: 0.8718\n",
      "2/2 [==============================] - 2s 23ms/step\n",
      "Accuracy: 0.8718, Precision: 0.8750, Recall: 0.8235, F1: 0.8485\n",
      "\n",
      "Fold 7\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 337ms/step - loss: 0.6922 - accuracy: 0.5803 - val_loss: 0.6730 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6802 - accuracy: 0.7268 - val_loss: 0.6663 - val_accuracy: 0.7179\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.6708 - accuracy: 0.7606 - val_loss: 0.6584 - val_accuracy: 0.7179\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.6587 - accuracy: 0.7803 - val_loss: 0.6505 - val_accuracy: 0.7179\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.6484 - accuracy: 0.7718 - val_loss: 0.6411 - val_accuracy: 0.7179\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6334 - accuracy: 0.7746 - val_loss: 0.6318 - val_accuracy: 0.7179\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6178 - accuracy: 0.7859 - val_loss: 0.6217 - val_accuracy: 0.7179\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6014 - accuracy: 0.8028 - val_loss: 0.6110 - val_accuracy: 0.6923\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5902 - accuracy: 0.7972 - val_loss: 0.5998 - val_accuracy: 0.6923\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5705 - accuracy: 0.8028 - val_loss: 0.5906 - val_accuracy: 0.7179\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5621 - accuracy: 0.8113 - val_loss: 0.5804 - val_accuracy: 0.7179\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5393 - accuracy: 0.8141 - val_loss: 0.5710 - val_accuracy: 0.7179\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5297 - accuracy: 0.8169 - val_loss: 0.5629 - val_accuracy: 0.7179\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5098 - accuracy: 0.8169 - val_loss: 0.5557 - val_accuracy: 0.7179\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4965 - accuracy: 0.8085 - val_loss: 0.5499 - val_accuracy: 0.7179\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.4865 - accuracy: 0.8169 - val_loss: 0.5451 - val_accuracy: 0.7436\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4765 - accuracy: 0.8254 - val_loss: 0.5395 - val_accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.4635 - accuracy: 0.8282 - val_loss: 0.5318 - val_accuracy: 0.7436\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4523 - accuracy: 0.8366 - val_loss: 0.5233 - val_accuracy: 0.7436\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.4335 - accuracy: 0.8479 - val_loss: 0.5084 - val_accuracy: 0.7436\n",
      "2/2 [==============================] - 3s 34ms/step\n",
      "Accuracy: 0.7436, Precision: 0.8182, Recall: 0.5294, F1: 0.6429\n",
      "\n",
      "Fold 8\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 13s 313ms/step - loss: 0.6967 - accuracy: 0.4761 - val_loss: 0.6842 - val_accuracy: 0.6410\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.6837 - accuracy: 0.6901 - val_loss: 0.6784 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6759 - accuracy: 0.7408 - val_loss: 0.6719 - val_accuracy: 0.7179\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6677 - accuracy: 0.7521 - val_loss: 0.6673 - val_accuracy: 0.7436\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.6598 - accuracy: 0.7746 - val_loss: 0.6622 - val_accuracy: 0.7179\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6516 - accuracy: 0.7718 - val_loss: 0.6546 - val_accuracy: 0.7436\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.6418 - accuracy: 0.7662 - val_loss: 0.6458 - val_accuracy: 0.7179\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6272 - accuracy: 0.7718 - val_loss: 0.6364 - val_accuracy: 0.7179\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.6137 - accuracy: 0.7775 - val_loss: 0.6266 - val_accuracy: 0.7692\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5979 - accuracy: 0.7831 - val_loss: 0.6169 - val_accuracy: 0.7692\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5825 - accuracy: 0.7775 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.5686 - accuracy: 0.7803 - val_loss: 0.5963 - val_accuracy: 0.7692\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5489 - accuracy: 0.8056 - val_loss: 0.5865 - val_accuracy: 0.7692\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5399 - accuracy: 0.7915 - val_loss: 0.5783 - val_accuracy: 0.7436\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.5319 - accuracy: 0.7915 - val_loss: 0.5705 - val_accuracy: 0.7436\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5165 - accuracy: 0.8085 - val_loss: 0.5624 - val_accuracy: 0.7436\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5091 - accuracy: 0.8028 - val_loss: 0.5530 - val_accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5000 - accuracy: 0.8000 - val_loss: 0.5440 - val_accuracy: 0.7436\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.4781 - accuracy: 0.8169 - val_loss: 0.5356 - val_accuracy: 0.7692\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.4673 - accuracy: 0.8169 - val_loss: 0.5257 - val_accuracy: 0.7692\n",
      "2/2 [==============================] - 3s 33ms/step\n",
      "Accuracy: 0.7692, Precision: 0.9000, Recall: 0.5294, F1: 0.6667\n",
      "\n",
      "Fold 9\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 13s 325ms/step - loss: 0.6795 - accuracy: 0.6451 - val_loss: 0.6720 - val_accuracy: 0.7179\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.6667 - accuracy: 0.7070 - val_loss: 0.6612 - val_accuracy: 0.7692\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.6537 - accuracy: 0.7493 - val_loss: 0.6486 - val_accuracy: 0.7949\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.6415 - accuracy: 0.7803 - val_loss: 0.6371 - val_accuracy: 0.7949\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6284 - accuracy: 0.7831 - val_loss: 0.6248 - val_accuracy: 0.8205\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6161 - accuracy: 0.8000 - val_loss: 0.6107 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5965 - accuracy: 0.8085 - val_loss: 0.5992 - val_accuracy: 0.8462\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5853 - accuracy: 0.8113 - val_loss: 0.5865 - val_accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5748 - accuracy: 0.7972 - val_loss: 0.5717 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5645 - accuracy: 0.8141 - val_loss: 0.5613 - val_accuracy: 0.8718\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5469 - accuracy: 0.8197 - val_loss: 0.5495 - val_accuracy: 0.8718\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.5309 - accuracy: 0.8169 - val_loss: 0.5370 - val_accuracy: 0.8718\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5249 - accuracy: 0.8141 - val_loss: 0.5249 - val_accuracy: 0.8718\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5123 - accuracy: 0.8338 - val_loss: 0.5124 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.5001 - accuracy: 0.8310 - val_loss: 0.4990 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.4939 - accuracy: 0.8423 - val_loss: 0.4874 - val_accuracy: 0.8718\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.4816 - accuracy: 0.8507 - val_loss: 0.4752 - val_accuracy: 0.8462\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.4645 - accuracy: 0.8563 - val_loss: 0.4637 - val_accuracy: 0.8462\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.4534 - accuracy: 0.8732 - val_loss: 0.4468 - val_accuracy: 0.8462\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.4300 - accuracy: 0.8817 - val_loss: 0.4167 - val_accuracy: 0.8974\n",
      "2/2 [==============================] - 3s 42ms/step\n",
      "Accuracy: 0.8974, Precision: 0.8421, Recall: 0.9412, F1: 0.8889\n",
      "\n",
      "Fold 10\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 12s 332ms/step - loss: 0.6901 - accuracy: 0.5183 - val_loss: 0.6760 - val_accuracy: 0.6410\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.6750 - accuracy: 0.6732 - val_loss: 0.6599 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.6633 - accuracy: 0.7127 - val_loss: 0.6438 - val_accuracy: 0.8462\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6486 - accuracy: 0.7746 - val_loss: 0.6300 - val_accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6372 - accuracy: 0.7887 - val_loss: 0.6124 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.6234 - accuracy: 0.8028 - val_loss: 0.5959 - val_accuracy: 0.8718\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.6089 - accuracy: 0.8282 - val_loss: 0.5749 - val_accuracy: 0.8718\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5865 - accuracy: 0.8338 - val_loss: 0.5550 - val_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.5754 - accuracy: 0.8451 - val_loss: 0.5384 - val_accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.5566 - accuracy: 0.8507 - val_loss: 0.5210 - val_accuracy: 0.8718\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5391 - accuracy: 0.8648 - val_loss: 0.5063 - val_accuracy: 0.8718\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5223 - accuracy: 0.8563 - val_loss: 0.4932 - val_accuracy: 0.8718\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5092 - accuracy: 0.8620 - val_loss: 0.4793 - val_accuracy: 0.8718\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.4947 - accuracy: 0.8732 - val_loss: 0.4701 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.4813 - accuracy: 0.8901 - val_loss: 0.4558 - val_accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4618 - accuracy: 0.8789 - val_loss: 0.4450 - val_accuracy: 0.8462\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4370 - accuracy: 0.8958 - val_loss: 0.4339 - val_accuracy: 0.8462\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.4166 - accuracy: 0.8958 - val_loss: 0.4221 - val_accuracy: 0.8462\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.3898 - accuracy: 0.9070 - val_loss: 0.4078 - val_accuracy: 0.8462\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.3666 - accuracy: 0.9070 - val_loss: 0.3970 - val_accuracy: 0.8462\n",
      "2/2 [==============================] - 2s 36ms/step\n",
      "Accuracy: 0.8462, Precision: 0.8667, Recall: 0.7647, F1: 0.8125\n",
      "\n",
      "Cross-Validation Summary:\n",
      "Avg Accuracy:  0.8298\n",
      "Avg Precision: 0.8861\n",
      "Avg Recall:    0.7065\n",
      "Avg F1-score:  0.7792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set up class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Prepare Stratified K-Fold\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_acc, all_prec, all_recall, all_f1 = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "\n",
    "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    model = build_fused_lstm_model()  # you already defined this\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_fold_train, y_fold_train,\n",
    "        validation_data=(X_fold_val, y_fold_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = (model.predict(X_fold_val) > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_fold_val, y_pred)\n",
    "    prec = precision_score(y_fold_val, y_pred)\n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    all_acc.append(acc)\n",
    "    all_prec.append(prec)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(f\"Avg Accuracy:  {np.mean(all_acc):.4f}\")\n",
    "print(f\"Avg Precision: {np.mean(all_prec):.4f}\")\n",
    "print(f\"Avg Recall:    {np.mean(all_recall):.4f}\")\n",
    "print(f\"Avg F1-score:  {np.mean(all_f1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a7eb8-2e92-482b-a370-05c7a00ef034",
   "metadata": {},
   "source": [
    "## Hold out set testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93be230e-d643-4297-8b07-85c18168f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 52ms/step\n",
      "\n",
      "Hold-Out Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.81      0.85      0.83        55\n",
      "        ADHD       0.80      0.75      0.78        44\n",
      "\n",
      "    accuracy                           0.81        99\n",
      "   macro avg       0.81      0.80      0.80        99\n",
      "weighted avg       0.81      0.81      0.81        99\n",
      "\n",
      "Confusion Matrix:\n",
      "[[47  8]\n",
      " [11 33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on test set\n",
    "y_test_probs = model.predict(X_test)\n",
    "y_test_pred = (y_test_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Print report\n",
    "print(\"\\nHold-Out Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Control\", \"ADHD\"]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c016fd-8d60-4206-9848-b9462cb11f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
